diff --git a/fast_cwdm/guided_diffusion/bratsloader.py b/fast_cwdm/guided_diffusion/bratsloader.py
index c78067e..976e2d1 100644
--- a/fast_cwdm/guided_diffusion/bratsloader.py
+++ b/fast_cwdm/guided_diffusion/bratsloader.py
@@ -5,13 +5,18 @@ import numpy as np
 import os
 import os.path
 import nibabel
+import hashlib
+import random
 
 class BRATSVolumes(torch.utils.data.Dataset):
-    def __init__(self, directory, mode='train', gen_type=None):
+    def __init__(self, directory, mode='train', gen_type=None, split='train', val_split_ratio=0.2, seed=42):
         super().__init__()
         self.mode = mode
         self.directory = os.path.expanduser(directory)
         self.gentype = gen_type
+        self.split = split  # 'train', 'val', or 'test'
+        self.val_split_ratio = val_split_ratio
+        self.seed = seed
         self.seqtypes = ['t1n', 't1c', 't2w', 't2f', 'seg']
 
         # VALIDATED DWT-compatible crop bounds: (160, 224, 160) - all even dimensions
@@ -22,17 +27,92 @@ class BRATSVolumes(torch.utils.data.Dataset):
             'z_min': 0,  'z_max': 160   # depth: 160
         }
         self.cropped_shape = (160, 224, 160)
+        self.dwt_shape = (80, 112, 80)  # DWT dimensions after transform
         print(f"üîß Using VALIDATED crop: 160x224x160 (DWT-compatible)")
 
+        # Build database and apply split
+        self._build_database()
+        self._apply_split()
+
+    def _build_database(self):
+        """Build complete database of all cases"""
         self.database = []
         for root, dirs, files in os.walk(self.directory):
             if not dirs:  # leaf directory with actual files
                 files.sort()
                 datapoint = dict()
                 for f in files:
-                    seqtype = f.split('-')[4].split('.')[0]
-                    datapoint[seqtype] = os.path.join(root, f)
-                self.database.append(datapoint)
+                    try:
+                        seqtype = f.split('-')[4].split('.')[0]
+                        datapoint[seqtype] = os.path.join(root, f)
+                    except IndexError:
+                        continue  # Skip files that don't match expected pattern
+                
+                # Only add if we have at least the 4 main modalities
+                required_modalities = ['t1n', 't1c', 't2w', 't2f']
+                if all(mod in datapoint for mod in required_modalities):
+                    self.database.append(datapoint)
+
+    def _apply_split(self):
+        """Apply train/val split based on deterministic hash of case path"""
+        if self.mode in ['eval', 'auto']:
+            # For evaluation modes, use all data
+            self.database = self.database
+            print(f"üìä {self.mode.upper()} mode: Using all {len(self.database)} cases")
+            return
+
+        # For training mode, apply train/val split
+        if self.split == 'test':
+            # This should use a different directory (validation data)
+            print(f"üìä TEST split: Using all {len(self.database)} cases from validation directory")
+            return
+
+        # Deterministic split based on case directory hash
+        random.seed(self.seed)  # Ensure reproducibility
+        
+        # Sort database for consistency
+        self.database.sort(key=lambda x: list(x.values())[0])
+        
+        # Create deterministic train/val split
+        total_cases = len(self.database)
+        val_size = int(total_cases * self.val_split_ratio)
+        
+        # Use hash-based split for determinism across runs
+        indices = list(range(total_cases))
+        random.shuffle(indices)  # Shuffle with fixed seed
+        
+        if self.split == 'train':
+            selected_indices = indices[val_size:]  # Training data
+        elif self.split == 'val':
+            selected_indices = indices[:val_size]   # Validation data
+        else:
+            raise ValueError(f"Unknown split: {self.split}")
+        
+        self.database = [self.database[i] for i in selected_indices]
+        
+        print(f"üìä {self.split.upper()} split: {len(self.database)}/{total_cases} cases "
+              f"(ratio: {len(self.database)/total_cases:.1%})")
+
+    def get_split_info(self):
+        """Get information about the current split"""
+        return {
+            'split': self.split,
+            'num_cases': len(self.database),
+            'val_split_ratio': self.val_split_ratio,
+            'seed': self.seed
+        }
+
+    def get_crop_info(self):
+        """Get crop bounds information"""
+        return f"crop bounds {self.crop_bounds} -> shape {self.cropped_shape}"
+    
+    def get_output_dimensions(self):
+        """Get output spatial dimensions"""
+        return self.cropped_shape
+    
+    def get_dwt_dimensions(self):
+        """Get DWT spatial dimensions"""
+        return self.dwt_shape
 
     def apply_crop(self, img_data):
         """Apply fixed crop bounds and pad if needed to DWT-compatible shape"""
@@ -40,6 +120,7 @@ class BRATSVolumes(torch.utils.data.Dataset):
         y_min, y_max = self.crop_bounds['y_min'], self.crop_bounds['y_max']
         z_min, z_max = self.crop_bounds['z_min'], self.crop_bounds['z_max']
         cropped = img_data[x_min:x_max, y_min:y_max, z_min:z_max]
+        
         # Pad if needed (shouldn't be needed, but robust)
         pad_shape = self.cropped_shape
         pad_width = [(0, max(0, pad_shape[i] - cropped.shape[i])) for i in range(3)]
diff --git a/fast_cwdm/guided_diffusion/train_util.py b/fast_cwdm/guided_diffusion/train_util.py
index c9776f5..ce3a421 100644
--- a/fast_cwdm/guided_diffusion/train_util.py
+++ b/fast_cwdm/guided_diffusion/train_util.py
@@ -2,6 +2,7 @@ import copy
 import functools
 import os
 import glob
+import time
 
 import blobfile as bf
 import torch as th
@@ -17,6 +18,9 @@ import numpy as np
 from . import dist_util, logger
 from .resample import LossAwareSampler, UniformSampler
 from fast_cwdm.DWT_IDWT.DWT_IDWT_layer import DWT_3D, IDWT_3D
+from fast_cwdm.guided_diffusion.synthesis_utils import (
+    ComprehensiveMetrics, synthesize_modality_shared, MODALITIES
+)
 
 INITIAL_LOG_LOSS_SCALE = 20.0
 
@@ -36,6 +40,7 @@ class TrainLoop:
         model,
         diffusion,
         data,
+        val_data=None,  # NEW: Validation dataset
         batch_size,
         in_channels,
         image_size,
@@ -45,6 +50,7 @@ class TrainLoop:
         log_interval,
         contr,
         save_interval,
+        val_interval=100,  # NEW: Validation interval
         resume_checkpoint,
         resume_step,
         use_fp16=False,
@@ -58,12 +64,14 @@ class TrainLoop:
         loss_level='image',
         sample_schedule='direct',
         diffusion_steps=1000,
+        early_stopping_patience=10,  # NEW: Early stopping
     ):
         self.summary_writer = summary_writer
         self.mode = mode
         self.model = model
         self.diffusion = diffusion
         self.datal = data
+        self.val_data = val_data  # NEW: Validation data
         self.dataset = dataset
         self.iterdatal = iter(data)
         self.batch_size = batch_size
@@ -79,6 +87,7 @@ class TrainLoop:
         )
         self.log_interval = log_interval
         self.save_interval = save_interval
+        self.val_interval = val_interval  # NEW
         self.resume_checkpoint = resume_checkpoint
         self.use_fp16 = use_fp16
         if self.use_fp16:
@@ -97,15 +106,25 @@ class TrainLoop:
         self.sync_cuda = th.cuda.is_available()
         self.sample_schedule = sample_schedule
         self.diffusion_steps = diffusion_steps
+        self.early_stopping_patience = early_stopping_patience
         
-        # NEW: Track best loss and checkpoint for each modality
-        self.best_losses = {}  # Will store best loss for each modality
-        self.best_checkpoints = {}  # Will store path to best checkpoint for each modality
+        # NEW: Enhanced validation tracking
+        self.best_val_ssim = -np.inf
+        self.steps_without_improvement = 0
+        self.best_checkpoint_path = None
         self.checkpoint_dir = os.path.join(get_blob_logdir(), 'checkpoints')
         os.makedirs(self.checkpoint_dir, exist_ok=True)
         
-        # Load existing best losses if resuming
-        self._load_best_losses()
+        # NEW: Metrics calculator for validation
+        if self.val_data is not None:
+            self.metrics_calculator = ComprehensiveMetrics(dist_util.dev())
+            print(f"üß† Validation enabled: {len(self.val_data)} cases, interval={self.val_interval}")
+        else:
+            self.metrics_calculator = None
+            print("‚ö†Ô∏è  No validation data provided")
+        
+        # Load existing best SSIM if resuming
+        self._load_best_metrics()
         
         self._load_and_sync_parameters()
         self.opt = AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)
@@ -117,32 +136,179 @@ class TrainLoop:
                 "Training requires CUDA. "
             )
 
-    def _load_best_losses(self):
-        """Load best losses from file if it exists"""
-        best_losses_file = os.path.join(self.checkpoint_dir, 'best_losses.txt')
-        if os.path.exists(best_losses_file):
+    def _load_best_metrics(self):
+        """Load best validation metrics from file if it exists"""
+        best_metrics_file = os.path.join(self.checkpoint_dir, 'best_val_metrics.txt')
+        if os.path.exists(best_metrics_file):
             try:
-                with open(best_losses_file, 'r') as f:
+                with open(best_metrics_file, 'r') as f:
                     for line in f:
-                        if line.strip():
-                            modality, loss_str = line.strip().split(':')
-                            self.best_losses[modality] = float(loss_str)
-                print(f"Loaded best losses: {self.best_losses}")
+                        if line.strip() and 'best_val_ssim:' in line:
+                            self.best_val_ssim = float(line.strip().split(':')[1])
+                print(f"Loaded best validation SSIM: {self.best_val_ssim:.4f}")
             except Exception as e:
-                print(f"Error loading best losses: {e}")
-                self.best_losses = {}
-        else:
-            self.best_losses = {}
+                print(f"Error loading best metrics: {e}")
+                self.best_val_ssim = -np.inf
 
-    def _save_best_losses(self):
-        """Save best losses to file"""
-        best_losses_file = os.path.join(self.checkpoint_dir, 'best_losses.txt')
+    def _save_best_metrics(self):
+        """Save best validation metrics to file"""
+        best_metrics_file = os.path.join(self.checkpoint_dir, 'best_val_metrics.txt')
         try:
-            with open(best_losses_file, 'w') as f:
-                for modality, loss in self.best_losses.items():
-                    f.write(f"{modality}:{loss}\n")
+            with open(best_metrics_file, 'w') as f:
+                f.write(f"best_val_ssim:{self.best_val_ssim}\n")
+                f.write(f"modality:{self.contr}\n")
+                f.write(f"step:{self.step + self.resume_step}\n")
         except Exception as e:
-            print(f"Error saving best losses: {e}")
+            print(f"Error saving best metrics: {e}")
+
+    def run_validation(self):
+        """
+        Run validation synthesis and calculate SSIM metrics.
+        Returns average validation SSIM.
+        """
+        if self.val_data is None or self.metrics_calculator is None:
+            return None
+        
+        print(f"\nüß™ Running validation at step {self.step + self.resume_step}...")
+        self.model.eval()
+        
+        val_metrics = []
+        val_start_time = time.time()
+        
+        # Sample a few validation cases for efficiency
+        max_val_cases = min(10, len(self.val_data))  # Limit for speed
+        val_indices = np.random.choice(len(self.val_data), max_val_cases, replace=False)
+        
+        with th.no_grad():
+            for i, val_idx in enumerate(val_indices):
+                try:
+                    batch = self.val_data[val_idx]
+                    
+                    # Move to device
+                    batch['t1n'] = batch['t1n'].to(dist_util.dev()).unsqueeze(0)  # Add batch dim
+                    batch['t1c'] = batch['t1c'].to(dist_util.dev()).unsqueeze(0)
+                    batch['t2w'] = batch['t2w'].to(dist_util.dev()).unsqueeze(0)
+                    batch['t2f'] = batch['t2f'].to(dist_util.dev()).unsqueeze(0)
+                    
+                    # Select target and conditioning modalities based on self.contr
+                    if self.contr == 't1n':
+                        target = batch['t1n'][0]  # Remove batch dim for metrics
+                        available_modalities = {'t1c': batch['t1c'], 't2w': batch['t2w'], 't2f': batch['t2f']}
+                    elif self.contr == 't1c':
+                        target = batch['t1c'][0]
+                        available_modalities = {'t1n': batch['t1n'], 't2w': batch['t2w'], 't2f': batch['t2f']}
+                    elif self.contr == 't2w':
+                        target = batch['t2w'][0]
+                        available_modalities = {'t1n': batch['t1n'], 't1c': batch['t1c'], 't2f': batch['t2f']}
+                    elif self.contr == 't2f':
+                        target = batch['t2f'][0]
+                        available_modalities = {'t1n': batch['t1n'], 't1c': batch['t1c'], 't2w': batch['t2w']}
+                    else:
+                        continue
+                    
+                    # Synthesize using shared function
+                    synthesized, metrics = synthesize_modality_shared(
+                        self.model, self.diffusion, available_modalities, self.contr,
+                        dist_util.dev(), self.metrics_calculator, target
+                    )
+                    
+                    if metrics and 'ssim' in metrics:
+                        val_metrics.append(metrics['ssim'])
+                        print(f"  Val case {i+1}/{max_val_cases}: SSIM={metrics['ssim']:.4f}")
+                    
+                except Exception as e:
+                    print(f"  Error in validation case {i+1}: {e}")
+                    continue
+        
+        self.model.train()  # Back to training mode
+        
+        val_end_time = time.time()
+        val_duration = val_end_time - val_start_time
+        
+        if val_metrics:
+            avg_val_ssim = np.mean(val_metrics)
+            std_val_ssim = np.std(val_metrics)
+            print(f"üß† Validation SSIM: {avg_val_ssim:.4f} ¬± {std_val_ssim:.4f} "
+                  f"({len(val_metrics)} cases, {val_duration:.1f}s)")
+            
+            # Log to wandb and tensorboard
+            wandb_log_dict = {
+                'val/ssim_mean': avg_val_ssim,
+                'val/ssim_std': std_val_ssim,
+                'val/num_cases': len(val_metrics),
+                'val/duration': val_duration,
+                'step': self.step + self.resume_step
+            }
+            wandb.log(wandb_log_dict, step=self.step + self.resume_step)
+            
+            if self.summary_writer is not None:
+                self.summary_writer.add_scalar('val/ssim_mean', avg_val_ssim, 
+                                               global_step=self.step + self.resume_step)
+                self.summary_writer.add_scalar('val/ssim_std', std_val_ssim,
+                                               global_step=self.step + self.resume_step)
+            
+            return avg_val_ssim
+        else:
+            print("‚ùå No valid validation metrics calculated")
+            return None
+
+    def save_if_best_val_ssim(self, val_ssim):
+        """Save checkpoint only if validation SSIM improves"""
+        if val_ssim is None:
+            return False
+        
+        is_best = val_ssim > self.best_val_ssim
+        
+        if is_best and dist.get_rank() == 0:
+            # Update best metrics
+            old_best = self.best_val_ssim
+            self.best_val_ssim = val_ssim
+            self.steps_without_improvement = 0
+            
+            print(f"üéØ NEW BEST VAL SSIM for {self.contr}! {old_best:.4f} ‚Üí {val_ssim:.4f}")
+            
+            # Remove old best checkpoint if it exists
+            if self.best_checkpoint_path and os.path.exists(self.best_checkpoint_path):
+                try:
+                    os.remove(self.best_checkpoint_path)
+                    print(f"Removed old checkpoint: {self.best_checkpoint_path}")
+                except Exception as e:
+                    print(f"Error removing old checkpoint: {e}")
+            
+            # Save new best checkpoint
+            filename = f"brats_{self.contr}_BEST_val_ssim_{val_ssim:.4f}_step_{(self.step+self.resume_step):06d}_{self.sample_schedule}_{self.diffusion_steps}.pt"
+            self.best_checkpoint_path = os.path.join(self.checkpoint_dir, filename)
+            
+            try:
+                with bf.BlobFile(self.best_checkpoint_path, "wb") as f:
+                    th.save(self.model.state_dict(), f)
+                
+                print(f"‚úÖ Saved new best checkpoint: {self.best_checkpoint_path}")
+                
+                # Save best metrics to file
+                self._save_best_metrics()
+                
+                # Save optimizer state for best model
+                opt_save_path = os.path.join(self.checkpoint_dir, f"opt_best_{self.contr}_val_ssim.pt")
+                with bf.BlobFile(opt_save_path, "wb") as f:
+                    th.save(self.opt.state_dict(), f)
+                print(f"üíæ Saved optimizer state: {opt_save_path}")
+                
+            except Exception as e:
+                print(f"‚ùå Error saving checkpoint: {e}")
+                return False
+            
+            return True
+        else:
+            if not is_best:
+                self.steps_without_improvement += 1
+                print(f"Val SSIM {val_ssim:.4f} not better than best {self.best_val_ssim:.4f} "
+                      f"({self.steps_without_improvement}/{self.early_stopping_patience} patience)")
+            return False
+
+    def should_early_stop(self):
+        """Check if early stopping criteria is met"""
+        return self.steps_without_improvement >= self.early_stopping_patience
 
     def _load_and_sync_parameters(self):
         resume_checkpoint = find_resume_checkpoint() or self.resume_checkpoint
@@ -180,11 +346,20 @@ class TrainLoop:
         total_step_time = 0.0
         total_log_time = 0.0
         total_save_time = 0.0
+        total_val_time = 0.0
         start_time = time.time()
         t = time.time()
+        
         while not self.lr_anneal_steps or self.step + self.resume_step < self.lr_anneal_steps:
+            # Check early stopping
+            if self.should_early_stop():
+                print(f"\nüõë Early stopping triggered after {self.steps_without_improvement} steps without improvement")
+                print(f"Best validation SSIM: {self.best_val_ssim:.4f}")
+                break
+            
             t_total = time.time() - t
             t = time.time()
+            
             # --- Data loading ---
             data_load_start = time.time()
             if self.dataset in ['brats']:
@@ -228,6 +403,8 @@ class TrainLoop:
                 'time/forward': total_step_time,
                 'time/total': t_total,
                 'loss/MSE': lossmse.item(),
+                'train/best_val_ssim': self.best_val_ssim,
+                'train/steps_without_improvement': self.steps_without_improvement,
                 'step': self.step + self.resume_step
             }
 
@@ -288,10 +465,18 @@ class TrainLoop:
             if self.step % self.log_interval == 0:
                 logger.dumpkvs()
 
-            # --- Saving (MODIFIED: Only save if best loss) ---
+            # --- NEW: Validation step ---
+            if self.step % self.val_interval == 0 and self.val_data is not None:
+                val_start = time.time()
+                val_ssim = self.run_validation()
+                self.save_if_best_val_ssim(val_ssim)
+                val_end = time.time()
+                total_val_time += val_end - val_start
+
+            # --- Saving (regular intervals for safety) ---
             if self.step % self.save_interval == 0:
                 save_start = time.time()
-                self.save_if_best(lossmse.item())
+                self.save_regular_checkpoint()
                 save_end = time.time()
                 total_save_time += save_end - save_start
                 if os.environ.get("DIFFUSION_TRAINING_TEST", "") and self.step > 0:
@@ -301,71 +486,42 @@ class TrainLoop:
             # Print profiling info every log_interval
             if self.step % self.log_interval == 0:
                 elapsed = time.time() - start_time
-                print(f"[PROFILE] Step {self.step}: Data {total_data_time:.2f}s, Step {total_step_time:.2f}s, Log {total_log_time:.2f}s, Save {total_save_time:.2f}s, Total {elapsed:.2f}s")
+                print(f"[PROFILE] Step {self.step}: Data {total_data_time:.2f}s, Step {total_step_time:.2f}s, "
+                      f"Log {total_log_time:.2f}s, Val {total_val_time:.2f}s, Save {total_save_time:.2f}s, Total {elapsed:.2f}s")
                 # Reset counters for next interval
                 total_data_time = 0.0
                 total_step_time = 0.0
                 total_log_time = 0.0
                 total_save_time = 0.0
-
-        # Save the last checkpoint if it wasn't already saved.
-        if (self.step - 1) % self.save_interval != 0:
-            self.save_if_best(lossmse.item())
-
-    def save_if_best(self, current_loss):
-        """Only save checkpoint if current loss is better than previous best"""
-        modality = self.contr
-        
-        # Check if this is the best loss so far
-        is_best = False
-        if modality not in self.best_losses or current_loss < self.best_losses[modality]:
-            is_best = True
-            self.best_losses[modality] = current_loss
-            
-        if is_best and dist.get_rank() == 0:
-            print(f"üéØ NEW BEST for {modality}! Loss: {current_loss:.6f}")
-            
-            # Remove old best checkpoint if it exists
-            if modality in self.best_checkpoints:
-                old_checkpoint = self.best_checkpoints[modality]
-                if os.path.exists(old_checkpoint):
-                    try:
-                        os.remove(old_checkpoint)
-                        print(f"Removed old checkpoint: {old_checkpoint}")
-                    except Exception as e:
-                        print(f"Error removing old checkpoint: {e}")
-            
-            # Save new best checkpoint
-            filename = f"brats_{self.contr}_{(self.step+self.resume_step):06d}_{self.sample_schedule}_{self.diffusion_steps}.pt"
+                total_val_time = 0.0
+
+        # Final validation and save
+        if self.val_data is not None:
+            final_val_ssim = self.run_validation()
+            self.save_if_best_val_ssim(final_val_ssim)
+            print(f"\nüéØ FINAL RESULTS:")
+            print(f"Best validation SSIM for {self.contr}: {self.best_val_ssim:.4f}")
+            if self.best_checkpoint_path:
+                print(f"Best model saved to: {self.best_checkpoint_path}")
+
+    def save_regular_checkpoint(self):
+        """Save regular checkpoint for safety (not necessarily best)"""
+        if dist.get_rank() == 0:
+            filename = f"brats_{self.contr}_step_{(self.step+self.resume_step):06d}_{self.sample_schedule}_{self.diffusion_steps}.pt"
             full_save_path = os.path.join(self.checkpoint_dir, filename)
             
             try:
                 with bf.BlobFile(full_save_path, "wb") as f:
                     th.save(self.model.state_dict(), f)
-                
-                self.best_checkpoints[modality] = full_save_path
-                print(f"‚úÖ Saved new best checkpoint: {full_save_path}")
-                
-                # Save best losses to file
-                self._save_best_losses()
-                
-                # Save optimizer state only for current best
-                opt_save_path = os.path.join(self.checkpoint_dir, f"opt_best_{modality}.pt")
-                with bf.BlobFile(opt_save_path, "wb") as f:
-                    th.save(self.opt.state_dict(), f)
-                print(f"üíæ Saved optimizer state: {opt_save_path}")
-                
+                print(f"üíæ Saved regular checkpoint: {filename}")
             except Exception as e:
-                print(f"‚ùå Error saving checkpoint: {e}")
-        else:
-            if not is_best:
-                print(f"Loss {current_loss:.6f} not better than best {self.best_losses.get(modality, float('inf')):.6f} for {modality}")
+                print(f"‚ùå Error saving regular checkpoint: {e}")
 
     def run_step(self, batch, cond, label=None, info=dict()):
         lossmse, sample, sample_idwt = self.forward_backward(batch, cond, label)
 
         if self.use_fp16:
-            self.grad_scaler.unscale_(self.opt)  # check self.grad_scaler._per_optimizer_states
+            self.grad_scaler.unscale_(self.opt)
 
         # compute norms
         with th.no_grad():
@@ -374,7 +530,7 @@ class TrainLoop:
             info['norm/param_max'] = param_max_norm
             info['norm/grad_max'] = grad_max_norm
 
-        if not th.isfinite(lossmse): #infinite
+        if not th.isfinite(lossmse):
             if not th.isfinite(th.tensor(param_max_norm)):
                 logger.log(f"Model parameters contain non-finite value {param_max_norm}, entering breakpoint", level=logger.ERROR)
                 breakpoint()
@@ -383,7 +539,6 @@ class TrainLoop:
                            "\n -> update will be skipped in grad_scaler.step()", level=logger.WARN)
 
         if self.use_fp16:
-            print("Use fp16 ...")
             self.grad_scaler.step(self.opt)
             self.grad_scaler.update()
             info['scale'] = self.grad_scaler.get_scale()
@@ -394,7 +549,7 @@ class TrainLoop:
         return lossmse, sample, sample_idwt
 
     def forward_backward(self, batch, cond, label=None):
-        for p in self.model.parameters():  # Zero out gradient
+        for p in self.model.parameters():
             p.grad = None
 
         if self.mode == 'i2i':
@@ -402,7 +557,6 @@ class TrainLoop:
         else:
             batch_size = batch.shape[0]
 
-        # Sample timesteps
         t, weights = self.schedule_sampler.sample(batch_size, dist_util.dev())
 
         compute_losses = functools.partial(
@@ -421,9 +575,9 @@ class TrainLoop:
             self.schedule_sampler.update_with_local_losses(
                 t, losses1["loss"].detach())
 
-        losses = losses1[0]         # Loss value
-        sample = losses1[1]         # Denoised subbands at t=0
-        sample_idwt = losses1[2]    # Inverse wavelet transformed denoised subbands at t=0
+        losses = losses1[0]
+        sample = losses1[1]
+        sample_idwt = losses1[2]
 
         # Log wavelet level loss
         if self.summary_writer is not None:
@@ -444,14 +598,13 @@ class TrainLoop:
             self.summary_writer.add_scalar('loss/mse_wav_hhh', losses["mse_wav"][7].item(),
                                            global_step=self.step + self.resume_step)
 
-        weights = th.ones(len(losses["mse_wav"])).cuda()  # Equally weight all wavelet channel losses
+        weights = th.ones(len(losses["mse_wav"])).cuda()
 
         loss = (losses["mse_wav"] * weights).mean()
         lossmse = loss.detach()
 
         log_loss_dict(self.diffusion, t, {k: v * weights for k, v in losses.items()})
 
-        # perform some finiteness checks
         if not th.isfinite(loss):
             logger.log(f"Encountered non-finite loss {loss}")
         if self.use_fp16:
@@ -474,44 +627,9 @@ class TrainLoop:
         logger.logkv("samples", (self.step + self.resume_step + 1) * self.global_batch)
 
     def save(self):
-        """Legacy save method - kept for compatibility but prints warning"""
-        print("‚ö†Ô∏è  Warning: Using legacy save(). Consider using save_if_best() instead.")
-        def save_checkpoint(rate, state_dict):
-            if dist.get_rank() == 0:
-                logger.log("Saving model...")
-                # Compose filename with modality, iterations, sample method, and timesteps
-                if self.dataset == 'brats':
-                    filename = f"brats_{self.contr}_{(self.step+self.resume_step):06d}_{self.sample_schedule}_{self.diffusion_steps}.pt"
-                elif self.dataset == 'lidc-idri':
-                    filename = f"lidc-idri_{self.contr}_{(self.step+self.resume_step):06d}_{self.sample_schedule}_{self.diffusion_steps}.pt"
-                elif self.dataset == 'brats_inpainting':
-                    filename = f"brats_inpainting_{self.contr}_{(self.step + self.resume_step):06d}_{self.sample_schedule}_{self.diffusion_steps}.pt"
-                elif self.dataset == 'synthrad':
-                    filename = f"synthrad_{self.contr}_{(self.step + self.resume_step):06d}_{self.sample_schedule}_{self.diffusion_steps}.pt"
-                else:
-                    raise ValueError(f'dataset {self.dataset} not implemented')
-
-                # Create checkpoints directory in /data/
-                checkpoint_dir = os.path.join(get_blob_logdir(), 'checkpoints')
-                os.makedirs(checkpoint_dir, exist_ok=True)
-                
-                full_save_path = os.path.join(checkpoint_dir, filename)
-                logger.log(f"Saving model to: {full_save_path}")
-                print(f"Saving model to: {full_save_path}")
-
-                with bf.BlobFile(full_save_path, "wb") as f:
-                    th.save(state_dict, f)
-
-        save_checkpoint(0, self.model.state_dict())
-
-        if dist.get_rank() == 0:
-            checkpoint_dir = os.path.join(get_blob_logdir(), 'checkpoints')
-            os.makedirs(checkpoint_dir, exist_ok=True)
-            opt_save_path = os.path.join(checkpoint_dir, f"opt{(self.step+self.resume_step):06d}.pt")
-            print(f"Saving optimizer to: {opt_save_path}")
-            
-            with bf.BlobFile(opt_save_path, "wb") as f:
-                th.save(self.opt.state_dict(), f)
+        """Legacy save method - prints deprecation warning"""
+        print("‚ö†Ô∏è  Warning: Using legacy save(). The enhanced training uses validation-based saving.")
+        self.save_regular_checkpoint()
 
 
 def parse_resume_step_from_filename(filename):
@@ -519,18 +637,16 @@ def parse_resume_step_from_filename(filename):
     Parse filenames of the form path/to/modelNNNNNN.pt, where NNNNNN is the
     checkpoint's number of steps.
     """
-
     split = os.path.basename(filename)
-    split = split.split(".")[-2]  # remove extension
-    split = split.split("_")[-1]  # remove possible underscores, keep only last word
-    # extract trailing number
+    split = split.split(".")[-2]
+    split = split.split("_")[-1]
     reversed_split = []
     for c in reversed(split):
         if not c.isdigit():
             break
         reversed_split.append(c)
     split = ''.join(reversed(reversed_split))
-    split = ''.join(c for c in split if c.isdigit())  # remove non-digits
+    split = ''.join(c for c in split if c.isdigit())
     try:
         return int(split)
     except ValueError:
@@ -541,20 +657,16 @@ def get_blob_logdir():
     """
     Modified to save checkpoints to /data/ directory where persistent volume is mounted
     """
-    # Save to /data/ directory instead of logger.get_dir()
     return "/data"
 
 
 def find_resume_checkpoint():
-    # On your infrastructure, you may want to override this to automatically
-    # discover the latest checkpoint on your blob storage, etc.
     return None
 
 
 def log_loss_dict(diffusion, ts, losses):
     for key, values in losses.items():
         logger.logkv_mean(key, values.mean().item())
-        # Log the quantiles (four quartiles, in particular).
         for sub_t, sub_loss in zip(ts.cpu().numpy(), values.detach().cpu().numpy()):
             quartile = int(4 * sub_t / diffusion.num_timesteps)
             logger.logkv_mean(f"{key}_q{quartile}", sub_loss)
\ No newline at end of file
diff --git a/fast_cwdm/run.sh b/fast_cwdm/run.sh
index 4455aa4..fff6910 100755
--- a/fast_cwdm/run.sh
+++ b/fast_cwdm/run.sh
@@ -1,13 +1,18 @@
 #!/bin/bash
 
-# Updated run.sh with VALIDATED WAVELET-FRIENDLY crop bounds
+# Enhanced run.sh with VALIDATED WAVELET-FRIENDLY crop bounds and improved validation strategy
 # 42% memory reduction, 100% brain preservation, DWT-compatible dimensions
+# NEW: Proper train/val split with validation-based model selection
 
 # Parse command line arguments
 SAMPLING_STRATEGY=""
 TIMESTEPS=""
 MODE="train"
 TRAIN_MODALITY="t1n"
+VAL_INTERVAL=100
+VAL_SPLIT_RATIO=0.2
+EARLY_STOPPING_PATIENCE=10
+
 while [[ $# -gt 0 ]]; do
   case $1 in
     --mode)
@@ -26,16 +31,50 @@ while [[ $# -gt 0 ]]; do
       TRAIN_MODALITY="$2"
       shift 2
       ;;
+    --val_interval)
+      VAL_INTERVAL="$2"
+      shift 2
+      ;;
+    --val_split_ratio)
+      VAL_SPLIT_RATIO="$2"
+      shift 2
+      ;;
+    --early_stopping_patience)
+      EARLY_STOPPING_PATIENCE="$2"
+      shift 2
+      ;;
     --help)
-      echo "Usage: $0 [--mode MODE] [--sampling-strategy STRATEGY] [--timesteps STEPS] [--train_modality MODALITY]"
-      echo "  --mode: train, sample, auto (default: train)"
-      echo "  --sampling-strategy: direct or sampled (default: direct)"
-      echo "  --timesteps: number of sampling steps (default: 0 for default 1000)"
-      echo "  --train_modality: t1n, t1c, t2w, t2f, all (default: t1n)"
+      echo "Usage: $0 [OPTIONS]"
+      echo ""
+      echo "OPTIONS:"
+      echo "  --mode MODE                    train, sample, auto (default: train)"
+      echo "  --sampling-strategy STRATEGY   direct or sampled (default: direct)"
+      echo "  --timesteps STEPS             number of sampling steps (default: 1000)"
+      echo "  --train_modality MODALITY     t1n, t1c, t2w, t2f, all (default: t1n)"
+      echo "  --val_interval STEPS          validation interval in steps (default: 100)"
+      echo "  --val_split_ratio RATIO       validation split ratio (default: 0.2)"
+      echo "  --early_stopping_patience N   early stopping patience (default: 10)"
+      echo ""
+      echo "VALIDATION FEATURES:"
+      echo "  - Automatic train/val split from training data"
+      echo "  - Brain-masked SSIM validation every --val_interval steps"
+      echo "  - Save best models based on validation SSIM"
+      echo "  - Early stopping if no improvement for --early_stopping_patience validations"
+      echo ""
+      echo "EXAMPLES:"
+      echo "  # Standard training with validation"
+      echo "  $0 --mode train --train_modality t1n"
+      echo ""
+      echo "  # Fast validation for debugging"
+      echo "  $0 --mode train --train_modality t1n --val_interval 50"
+      echo ""
+      echo "  # Different validation split"
+      echo "  $0 --mode train --train_modality t1n --val_split_ratio 0.15"
       exit 0
       ;;
     *)
       echo "Unknown option $1"
+      echo "Use --help for usage information"
       exit 1
       ;;
   esac
@@ -58,17 +97,27 @@ if [[ -z "$TIMESTEPS" ]]; then
   TIMESTEPS=1000
 fi
 
-
-# Print validated crop bounds info (used everywhere)
-echo "üîß USING VALIDATED DWT-FRIENDLY CROP BOUNDS (used everywhere)"
+# Print enhanced training info
+echo "üß† ENHANCED FAST-CWDM TRAINING WITH VALIDATION"
+echo "=============================================="
+echo ""
+echo "üîß VALIDATED DWT-FRIENDLY CROP BOUNDS (used everywhere)"
 echo "   Crop bounds: (39:199, 17:225, 0:160)"
 echo "   Output dims: 160x224x160 (42% memory reduction)"
-echo "   DWT dims: 80x104x76 (perfect wavelet compatibility)"
+echo "   DWT dims: 80x112x80 (perfect wavelet compatibility)"
 echo "   Brain preservation: 100% validated"
+echo ""
+echo "üß™ VALIDATION STRATEGY"
+echo "   Val split ratio: $VAL_SPLIT_RATIO (${VAL_SPLIT_RATIO%.*}% for validation)"
+echo "   Val interval: every $VAL_INTERVAL training steps"
+echo "   Early stopping: after $EARLY_STOPPING_PATIENCE validations without improvement"
+echo "   Metric: Brain-masked SSIM (correlates with synthesis quality)"
+echo "   Model selection: Save best validation SSIM, not training loss"
+echo ""
 
 # detailed settings updated for validated crop bounds
 if [[ $MODEL == 'unet' ]]; then
-  echo "MODEL: WDM (U-Net) with validated crop bounds";
+  echo "MODEL: WDM (U-Net) with validated crop bounds and enhanced validation";
   CHANNEL_MULT=1,2,2,4,4;
   ADDITIVE_SKIP=False;      # Set True to save memory
   BATCH_SIZE=2;
@@ -82,13 +131,17 @@ else
 fi
 
 # Print the values being used
-echo "Using sampling strategy: $SAMPLE_SCHEDULE"
-echo "Using timesteps: $TIMESTEPS"
-echo "Using image size: $IMAGE_SIZE (height from validated crop)"
+echo "‚öôÔ∏è  CONFIGURATION"
+echo "   Sampling strategy: $SAMPLE_SCHEDULE"
+echo "   Timesteps: $TIMESTEPS"
+echo "   Image size: $IMAGE_SIZE (height from validated crop)"
+echo "   Mode: $MODE"
+echo "   Train modality: $TRAIN_MODALITY"
 
 # Set data directories based on mode and dataset
 if [[ $MODE == 'train' ]]; then
-  echo "MODE: training with validated crop bounds";
+  echo ""
+  echo "üöÇ MODE: Enhanced training with validation and crop bounds";
   if [[ $DATASET == 'brats' ]]; then
     echo "DATASET: BRATS";
     DATA_DIR=./datasets/BRATS2023/training;
@@ -98,7 +151,8 @@ if [[ $MODE == 'train' ]]; then
 
 elif [[ $MODE == 'sample' ]]; then
   BATCH_SIZE=1;
-  echo "MODE: sampling (image-to-image translation) with validated crop bounds";
+  echo ""
+  echo "üîç MODE: sampling (image-to-image translation) with validated crop bounds";
   if [[ $DATASET == 'brats' ]]; then
     echo "DATASET: BRATS";
     DATA_DIR=./datasets/BRATS2023/validation;
@@ -108,7 +162,8 @@ elif [[ $MODE == 'sample' ]]; then
 
 elif [[ $MODE == 'auto' ]]; then
   BATCH_SIZE=1;
-  echo "MODE: sampling in automatic mode with validated crop bounds";
+  echo ""
+  echo "ü§ñ MODE: sampling in automatic mode with validated crop bounds";
   if [[ $DATASET == 'brats' ]]; then
     echo "DATASET: BRATS";
     DATA_DIR=./datasets/BRATS2023/pseudo_validation;
@@ -154,7 +209,10 @@ TRAIN="
 --image_size=${IMAGE_SIZE}
 --use_fp16=False
 --lr=1e-5
---save_interval=50
+--save_interval=500
+--val_interval=${VAL_INTERVAL}
+--val_split_ratio=${VAL_SPLIT_RATIO}
+--early_stopping_patience=${EARLY_STOPPING_PATIENCE}
 --num_workers=12
 --devices=${GPU}
 "
@@ -174,59 +232,82 @@ SAMPLE="
 --clip_denoised=True
 "
 
+echo ""
+echo "üöÄ STARTING EXECUTION"
+echo "====================="
+
 # Run the appropriate script based on mode
 if [[ $MODE == 'train' ]]; then
   if [[ $TRAIN_MODALITY == 'all' ]]; then
-    echo "Training all modalities with validated crop bounds";
+    echo ""
+    echo "üîÑ Training all modalities with enhanced validation";
     MODALITIES=("t1n" "t1c" "t2w" "t2f")
     for CONTRAST in "${MODALITIES[@]}"; do
       CONTR=$CONTRAST
-      echo "Training for modality: $CONTRAST"
-      echo "Expected memory reduction: ~42% vs original"
+      echo ""
+      echo "üìä Training modality: $CONTRAST"
+      echo "   Expected memory reduction: ~42% vs original"
+      echo "   Validation: Every $VAL_INTERVAL steps with brain-masked SSIM"
+      echo "   Early stopping: After $EARLY_STOPPING_PATIENCE validations without improvement"
       START_TIME=$(date +%s)
       python scripts/train.py $TRAIN --contr=${CONTR} $COMMON
       END_TIME=$(date +%s)
       ELAPSED=$((END_TIME - START_TIME))
-      echo "[TIMING] Training for $CONTRAST completed in $ELAPSED seconds ($((ELAPSED/60)) min $((ELAPSED%60)) sec)"
-      echo "‚úÖ $CONTRAST training completed with validated crop bounds"
+      echo ""
+      echo "‚è±Ô∏è  [TIMING] Training for $CONTRAST completed in $ELAPSED seconds ($((ELAPSED/60)) min $((ELAPSED%60)) sec)"
+      echo "‚úÖ $CONTRAST training completed with enhanced validation"
     done
   else
     # single-modality case
-    echo "Training single modality: $TRAIN_MODALITY with validated crop bounds"
-    echo "Expected memory reduction: ~42% vs original"
+    echo ""
+    echo "üìä Training single modality: $TRAIN_MODALITY"
+    echo "   Expected memory reduction: ~42% vs original"
+    echo "   Validation: Every $VAL_INTERVAL steps with brain-masked SSIM"
+    echo "   Early stopping: After $EARLY_STOPPING_PATIENCE validations without improvement"
     START_TIME=$(date +%s)
     python scripts/train.py $TRAIN --contr=${CONTR} $COMMON
     END_TIME=$(date +%s)
     ELAPSED=$((END_TIME - START_TIME))
-    echo "[TIMING] Training for $TRAIN_MODALITY completed in $ELAPSED seconds ($((ELAPSED/60)) min $((ELAPSED%60)) sec)"
-    echo "‚úÖ $TRAIN_MODALITY training completed with validated crop bounds"
+    echo ""
+    echo "‚è±Ô∏è  [TIMING] Training for $TRAIN_MODALITY completed in $ELAPSED seconds ($((ELAPSED/60)) min $((ELAPSED%60)) sec)"
+    echo "‚úÖ $TRAIN_MODALITY training completed with enhanced validation"
   fi
 
 elif [[ $MODE == 'sample' ]]; then
-  echo "Timing sampling run with validated crop bounds..."
+  echo ""
+  echo "üîç Timing sampling run with validated crop bounds..."
   START_TIME=$(date +%s)
   python scripts/sample.py $SAMPLE $COMMON --contr=${CONTR}
   END_TIME=$(date +%s)
   ELAPSED=$((END_TIME - START_TIME))
-  echo "[TIMING] Sampling completed in $ELAPSED seconds ($((ELAPSED/60)) min $((ELAPSED%60)) sec)"
+  echo ""
+  echo "‚è±Ô∏è  [TIMING] Sampling completed in $ELAPSED seconds ($((ELAPSED/60)) min $((ELAPSED%60)) sec)"
   echo "‚úÖ Sampling completed with validated crop bounds"
 
 elif [[ $MODE == 'auto' ]]; then
-  echo "Timing auto-sampling run with validated crop bounds..."
+  echo ""
+  echo "ü§ñ Timing auto-sampling run with validated crop bounds..."
   START_TIME=$(date +%s)
   python scripts/sample_auto.py $SAMPLE $COMMON
   END_TIME=$(date +%s)
   ELAPSED=$((END_TIME - START_TIME))
-  echo "[TIMING] Auto-sampling completed in $ELAPSED seconds ($((ELAPSED/60)) min $((ELAPSED%60)) sec)"
+  echo ""
+  echo "‚è±Ô∏è  [TIMING] Auto-sampling completed in $ELAPSED seconds ($((ELAPSED/60)) min $((ELAPSED%60)) sec)"
   echo "‚úÖ Auto-sampling completed with validated crop bounds"
 
 else
-  echo "MODE NOT FOUND -> Check the supported modes again";
+  echo "‚ùå MODE NOT FOUND -> Check the supported modes again";
 fi
 
 echo ""
-echo "üéØ VALIDATED CROP BOUNDS IMPLEMENTATION COMPLETE"
-echo "   Memory efficiency: ~42% reduction"
+echo "üéØ ENHANCED FAST-CWDM IMPLEMENTATION COMPLETE"
+echo "============================================="
+echo "   Memory efficiency: ~42% reduction vs original"
 echo "   Brain preservation: 100% validated"
 echo "   DWT compatibility: Perfect"
-echo "   Dimensions: 160x224x155 ‚Üí 80x104x77 (DWT)"
\ No newline at end of file
+echo "   Validation strategy: Brain-masked SSIM with early stopping"
+echo "   Model selection: Best validation performance, not training loss"
+echo "   Dimensions: 160x224x160 ‚Üí 80x112x80 (DWT)"
+echo ""
+echo "üèÜ Best models are saved based on validation SSIM in /data/checkpoints/"
+echo "   Look for files with 'BEST_val_ssim' in the name"
\ No newline at end of file
diff --git a/fast_cwdm/scripts/complete_dataset.py b/fast_cwdm/scripts/complete_dataset.py
index aa23b9f..f692da1 100644
--- a/fast_cwdm/scripts/complete_dataset.py
+++ b/fast_cwdm/scripts/complete_dataset.py
@@ -1,11 +1,8 @@
 #!/usr/bin/env python3
 """
-Enhanced medical image synthesis script with SSIM evaluation
-Uses VALIDATED WAVELET-FRIENDLY crop bounds from dataset analysis
-- 42% memory reduction with 100% brain/segmentation preservation
-- DWT-compatible dimensions (160x224x155)
-- Proper preprocessing matching training dataloader
-FIXED: All dimension mismatches and hardcoded assumptions
+Enhanced medical image synthesis script using SHARED synthesis utilities.
+This ensures 100% consistency between training validation and inference.
+Uses VALIDATED WAVELET-FRIENDLY crop bounds from dataset analysis.
 """
 
 import argparse
@@ -28,114 +25,10 @@ from fast_cwdm.guided_diffusion.script_util import (
     args_to_dict
 )
 from fast_cwdm.guided_diffusion.bratsloader import clip_and_normalize
-from fast_cwdm.DWT_IDWT.DWT_IDWT_layer import IDWT_3D, DWT_3D
-from monai.metrics import SSIMMetric, PSNRMetric
-import torch.nn.functional as F
-
-# VALIDATED WAVELET-FRIENDLY CROP BOUNDS from analysis
-CROP_BOUNDS = {
-    'x_min': 39, 'x_max': 199,  # width: 160 (divisible by 16)
-    'y_min': 9, 'y_max': 233,  # height: 224 (divisible by 16)
-    'z_min': 0,  'z_max': 160   # depth: 155 (original)
-}
-
-ORIGINAL_SHAPE = (240, 240, 160)
-CROPPED_SHAPE = (160, 224, 160)
-MODALITIES = ['t1n', 't1c', 't2w', 't2f']
-
-def create_brain_mask_from_target(target, threshold=0.01):
-    """Create brain mask from target image"""
-    if target.dim() > 3:
-        # Remove batch/channel dimensions for mask creation
-        target_for_mask = target.squeeze()
-    else:
-        target_for_mask = target
-    
-    brain_mask = (target_for_mask > threshold).float()
-    
-    # Ensure mask has same dimensions as target
-    while brain_mask.dim() < target.dim():
-        brain_mask = brain_mask.unsqueeze(0)
-    
-    return brain_mask
-
-class ComprehensiveMetrics:
-    """Calculate comprehensive metrics for synthesis evaluation with brain masking"""
-    
-    def __init__(self, device='cuda'):
-        self.device = device
-        self.ssim_metric = SSIMMetric(
-            spatial_dims=3,
-            data_range=1.0,
-            win_size=7,  # Smaller window for medical images
-            k1=0.01,
-            k2=0.03
-        )
-        self.psnr_metric = PSNRMetric(max_val=1.0)
-        
-    def calculate_metrics(self, predicted, target, case_name=""):
-        """Calculate L1, MSE, PSNR, and SSIM metrics with brain masking"""
-        metrics = {}
-        
-        with th.no_grad():
-            # Ensure tensors are on the same device
-            predicted = predicted.to(self.device)
-            target = target.to(self.device)
-            
-            # Add channel dimension if needed
-            if predicted.dim() == 3:  # [H, W, D]
-                predicted = predicted.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W, D]
-            elif predicted.dim() == 4:  # [B, H, W, D] or [1, H, W, D]
-                predicted = predicted.unsqueeze(1)  # [B, 1, H, W, D]
-                
-            if target.dim() == 3:
-                target = target.unsqueeze(0).unsqueeze(0)
-            elif target.dim() == 4:
-                target = target.unsqueeze(1)
-            
-            # üß† CREATE BRAIN MASK FROM TARGET (GROUND TRUTH)
-            brain_mask = create_brain_mask_from_target(target, threshold=0.01)
-            
-            # üß† APPLY MASK TO BOTH PREDICTED AND TARGET
-            predicted_masked = predicted * brain_mask
-            target_masked = target * brain_mask
-            
-            # Calculate metrics on MASKED images only
-            l1_loss = F.l1_loss(predicted_masked, target_masked).item()
-            mse_loss = F.mse_loss(predicted_masked, target_masked).item()
-            
-            # PSNR on masked images
-            try:
-                psnr_score = self.psnr_metric(y_pred=predicted_masked, y=target_masked).mean().item()
-            except Exception as e:
-                print(f"  Warning: PSNR calculation failed for {case_name}: {e}")
-                psnr_score = 0.0
-            
-            # SSIM on masked images - KEY IMPROVEMENT!
-            try:
-                ssim_score = self.ssim_metric(y_pred=predicted_masked, y=target_masked).mean().item()
-            except Exception as e:
-                print(f"  Warning: SSIM calculation failed for {case_name}: {e}")
-                ssim_score = 0.0
-            
-            # Calculate brain volume for debugging/reporting
-            brain_volume = brain_mask.sum().item()
-            total_volume = brain_mask.numel()
-            brain_ratio = brain_volume / total_volume
-            
-            metrics = {
-                'l1': l1_loss,
-                'mse': mse_loss,
-                'psnr': psnr_score,
-                'ssim': ssim_score,
-                'brain_volume_ratio': brain_ratio
-            }
-            
-            if case_name:
-                print(f"  {case_name}: SSIM={ssim_score:.4f} (brain region = {brain_ratio:.1%})")
-            
-        return metrics
-
+from fast_cwdm.guided_diffusion.synthesis_utils import (
+    ComprehensiveMetrics, synthesize_modality_shared, apply_uncrop_to_original,
+    CROP_BOUNDS, ORIGINAL_SHAPE, CROPPED_SHAPE, MODALITIES
+)
 
 def apply_optimal_crop(img_data):
     """Apply validated wavelet-friendly crop bounds"""
@@ -145,24 +38,6 @@ def apply_optimal_crop(img_data):
         CROP_BOUNDS['z_min']:CROP_BOUNDS['z_max']
     ]
 
-
-def apply_uncrop(cropped_output):
-    """Uncrop from (160,224,155) back to (240,240,155)"""
-    if isinstance(cropped_output, th.Tensor):
-        uncropped = th.zeros(ORIGINAL_SHAPE, dtype=cropped_output.dtype, device=cropped_output.device)
-    else:
-        uncropped = np.zeros(ORIGINAL_SHAPE, dtype=cropped_output.dtype)
-    
-    # Place cropped output back in original position
-    uncropped[
-        CROP_BOUNDS['x_min']:CROP_BOUNDS['x_max'],
-        CROP_BOUNDS['y_min']:CROP_BOUNDS['y_max'],
-        CROP_BOUNDS['z_min']:CROP_BOUNDS['z_max']
-    ] = cropped_output
-    
-    return uncropped
-
-
 def load_image(file_path):
     """Load and preprocess image EXACTLY like training dataloader with optimal crop."""
     print(f"Loading: {file_path}")
@@ -179,16 +54,15 @@ def load_image(file_path):
     print(f"  After optimal crop: {img_cropped.shape}")
     
     # Convert to tensor with proper dimensions for DWT
-    # Shape should be (160, 224, 155) -> ready for DWT
+    # Shape should be (160, 224, 160) -> ready for DWT
     img_tensor = th.tensor(img_cropped).float()
     
-    # Add batch dimension: (1, 160, 224, 155)
+    # Add batch dimension: (1, 160, 224, 160)
     img_tensor = img_tensor.unsqueeze(0)
     
     print(f"  Final tensor shape: {img_tensor.shape}")
     return img_tensor
 
-
 def find_missing_modality(case_dir, evaluation_mode=False, target_modality=None):
     """Find which modality is missing (real) or select one to exclude (evaluation)."""
     case_name = os.path.basename(case_dir)
@@ -209,7 +83,6 @@ def find_missing_modality(case_dir, evaluation_mode=False, target_modality=None)
                 return modality
         return None
 
-
 def check_complete_case(case_dir):
     """Check if case has all 4 modalities (for evaluation mode)."""
     case_name = os.path.basename(case_dir)
@@ -220,7 +93,6 @@ def check_complete_case(case_dir):
             return False
     return True
 
-
 def load_available_modalities(case_dir, missing_modality, evaluation_mode=False):
     """Load all available modalities (excluding the missing/target one)."""
     case_name = os.path.basename(case_dir)
@@ -236,16 +108,28 @@ def load_available_modalities(case_dir, missing_modality, evaluation_mode=False)
     
     return modalities
 
-
 def find_checkpoint(missing_modality, checkpoint_dir):
     """Find the best checkpoint for the missing modality."""
-    # Look for BEST checkpoints first
-    pattern = f"brats_{missing_modality}_*.pt"
+    # Look for BEST validation SSIM checkpoints first
+    pattern = f"brats_{missing_modality}_BEST_val_ssim_*.pt"
     best_files = glob.glob(os.path.join(checkpoint_dir, pattern))
     
     if best_files:
+        # Sort by SSIM score (higher is better)
+        def get_ssim_score(filename):
+            try:
+                parts = os.path.basename(filename).split('_')
+                for i, part in enumerate(parts):
+                    if part == "ssim" and i + 1 < len(parts):
+                        return float(parts[i + 1])
+            except (ValueError, IndexError):
+                pass
+            return 0.0
+        
+        best_files.sort(key=get_ssim_score, reverse=True)
         checkpoint = best_files[0]
-        print(f"Found checkpoint: {checkpoint}")
+        ssim_score = get_ssim_score(checkpoint)
+        print(f"Found BEST validation checkpoint: {checkpoint} (SSIM: {ssim_score:.4f})")
         return checkpoint
     
     # Fallback to regular checkpoints
@@ -265,12 +149,11 @@ def find_checkpoint(missing_modality, checkpoint_dir):
     
     regular_files.sort(key=get_iteration, reverse=True)
     checkpoint = regular_files[0]
-    print(f"Found checkpoint: {checkpoint}")
+    print(f"Found regular checkpoint: {checkpoint}")
     return checkpoint
 
-
 def parse_checkpoint_info(checkpoint_path):
-    """Parse checkpoint filename to get training parameters - FIXED VERSION."""
+    """Parse checkpoint filename to get training parameters - ENHANCED VERSION."""
     basename = os.path.basename(checkpoint_path)
     
     # Default values
@@ -279,42 +162,31 @@ def parse_checkpoint_info(checkpoint_path):
     
     print(f"Parsing checkpoint: {basename}")
     
-    # Handle different checkpoint naming patterns
-    
-    # Pattern 1: brats_t1n_BEST100epoch_sampled_10.pt
-    if "_BEST100epoch_" in basename:
+    # Pattern 1: BEST validation checkpoints
+    if "_BEST_val_ssim_" in basename:
         parts = basename.split('_')
-        if len(parts) >= 4:
-            sample_schedule = parts[3]
-        if len(parts) >= 5:
-            try:
-                diffusion_steps = int(parts[4].split('.')[0])
-            except ValueError:
-                pass
+        # Look for sample schedule and steps in the filename
+        for i, part in enumerate(parts):
+            if part in ["direct", "sampled"]:
+                sample_schedule = part
+            elif part.isdigit() and len(part) >= 2:
+                diffusion_steps = int(part)
     
-    # Pattern 2: brats_t1c_074500_sampled_100.pt (YOUR FORMAT)
+    # Pattern 2: Regular checkpoints
     elif "_sampled_" in basename:
         parts = basename.split('_')
         for i, part in enumerate(parts):
             if part == "sampled" and i + 1 < len(parts):
                 try:
                     diffusion_steps = int(parts[i + 1].split('.')[0])
-                    sample_schedule = "sampled"  # Fixed: should be "sampled" not "direct"
+                    sample_schedule = "sampled"
                     break
                 except ValueError:
                     pass
     
-    # Pattern 3: Look for any number after "sampled" using regex
-    else:
-        match = re.search(r'sampled[_-](\d+)', basename)
-        if match:
-            diffusion_steps = int(match.group(1))
-            sample_schedule = "sampled"  # Fixed: should be "sampled"
-    
     print(f"‚úÖ Checkpoint config: schedule={sample_schedule}, steps={diffusion_steps}")
     return sample_schedule, diffusion_steps
 
-
 def create_model_args(sample_schedule="direct", diffusion_steps=1000):
     """Create model arguments with UPDATED dimensions for optimal crop."""
     class Args:
@@ -323,7 +195,7 @@ def create_model_args(sample_schedule="direct", diffusion_steps=1000):
     args = Args()
     
     # Model architecture - UPDATED for optimal crop dimensions
-    args.image_size = 224  # Height from cropped dimensions (was 224)
+    args.image_size = 224  # Height from cropped dimensions
     args.num_channels = 64
     args.num_res_blocks = 2
     args.channel_mult = "1,2,2,4,4"
@@ -366,52 +238,12 @@ def create_model_args(sample_schedule="direct", diffusion_steps=1000):
     
     return args
 
-
-def prepare_conditioning(available_modalities, missing_modality, device):
-    """Prepare conditioning tensor from available modalities with FIXED dimensions."""
-    dwt = DWT_3D("haar")
-    
-    # Get modalities in consistent order
-    available_order = [m for m in MODALITIES if m != missing_modality]
-    print(f"Available modalities: {available_order}")
-    
-    cond_list = []
-    
-    for modality in available_order:
-        # Get tensor and add channel dimension
-        tensor = available_modalities[modality].to(device)
-        if tensor.dim() == 4:
-            tensor = tensor.unsqueeze(1)  # [B, 1, H, W, D]
-        
-        print(f"  {modality} input shape: {tensor.shape}")
-        
-        # Apply DWT - should work perfectly with (160, 224, 155) dimensions
-        dwt_components = dwt(tensor)
-        shapes = [c.shape for c in dwt_components]
-        print(f"  {modality} DWT shapes: {shapes}")
-        
-        # All components should have consistent dimensions now
-        LLL, LLH, LHL, LHH, HLL, HLH, HHL, HHH = dwt_components
-        
-        # Create DWT conditioning tensor
-        modality_cond = th.cat([
-            LLL / 3.,  # Divide LLL by 3 as per training
-            LLH, LHL, LHH, HLL, HLH, HHL, HHH
-        ], dim=1)
-        
-        print(f"  {modality} final conditioning: {modality_cond.shape}")
-        cond_list.append(modality_cond)
-    
-    # Concatenate all modalities
-    cond = th.cat(cond_list, dim=1)
-    print(f"Final conditioning shape: {cond.shape}")
-    
-    return cond
-
-
-def synthesize_modality(available_modalities, missing_modality, checkpoint_path, device, metrics_calculator=None, target_data=None, override_steps=None):
-    """Synthesize the missing modality with comprehensive metrics."""
-    print(f"\n=== Synthesizing {missing_modality} ===")
+def synthesize_modality(available_modalities, missing_modality, checkpoint_path, device, 
+                       metrics_calculator=None, target_data=None, override_steps=None):
+    """
+    Synthesize using SHARED synthesis utilities - ensures 100% consistency with training validation.
+    """
+    print(f"\n=== Synthesizing {missing_modality} (SHARED PIPELINE) ===")
     
     # Parse checkpoint info
     sample_schedule, diffusion_steps = parse_checkpoint_info(checkpoint_path)
@@ -435,38 +267,19 @@ def synthesize_modality(available_modalities, missing_modality, checkpoint_path,
     model.to(device)
     model.eval()
     
-    # Prepare conditioning
-    cond = prepare_conditioning(available_modalities, missing_modality, device)
-    
-    # Create noise tensor with CORRECT dimensions based on DWT output
-    # Conditioning shape should be [B, 24, D/2, H/2, W/2] for 3 modalities
-    _, _, cond_d, cond_h, cond_w = cond.shape
-    noise_shape = (1, 8, cond_d, cond_h, cond_w)  # Match DWT dimensions
-    noise = th.randn(*noise_shape, device=device)
-    
-    print(f"Noise shape: {noise.shape}")
-    print(f"Conditioning shape: {cond.shape}")
-    
-    # Sample using p_sample_loop_progressive (correct method for Fast-DDPM)
-    print(f"üöÄ Running {diffusion.num_timesteps}-step sampling...")
-    
     # Start timing
     sample_start_time = time.time()
     
-    with th.no_grad():
-        final_sample = None
-        for sample_dict in diffusion.p_sample_loop_progressive(
-            model=model,
-            shape=noise.shape,
-            time=diffusion.num_timesteps,  # ‚úÖ Correct parameter for fast sampling
-            noise=noise,
-            cond=cond,
-            clip_denoised=True,
-            model_kwargs={}
-        ):
-            final_sample = sample_dict
-        
-        sample = final_sample["sample"]
+    # Use SHARED synthesis function - guarantees consistency with training validation
+    synthesized, metrics = synthesize_modality_shared(
+        model=model,
+        diffusion=diffusion,
+        available_modalities=available_modalities,
+        missing_modality=missing_modality,
+        device=device,
+        metrics_calculator=metrics_calculator,
+        target_data=target_data
+    )
     
     # End timing
     sample_end_time = time.time()
@@ -474,69 +287,14 @@ def synthesize_modality(available_modalities, missing_modality, checkpoint_path,
     
     print(f"‚è±Ô∏è Sampling completed in {sample_duration:.2f} seconds ({sample_duration/60:.2f} minutes)")
     
-    # Return timing info along with other data
-    timing_info = {
-        'sample_time': sample_duration,
-        'steps': diffusion.num_timesteps
-    }
-    
-    print(f"Sample shape: {sample.shape}")
-    
-    # Convert back to spatial domain using IDWT
-    idwt = IDWT_3D("haar")
-    B, _, D, H, W = sample.shape
-    
-    spatial_sample = idwt(
-        sample[:, 0, :, :, :].view(B, 1, D, H, W) * 3.,  # Multiply LLL by 3
-        sample[:, 1, :, :, :].view(B, 1, D, H, W),
-        sample[:, 2, :, :, :].view(B, 1, D, H, W),
-        sample[:, 3, :, :, :].view(B, 1, D, H, W),
-        sample[:, 4, :, :, :].view(B, 1, D, H, W),
-        sample[:, 5, :, :, :].view(B, 1, D, H, W),
-        sample[:, 6, :, :, :].view(B, 1, D, H, W),
-        sample[:, 7, :, :, :].view(B, 1, D, H, W)
-    )
-    
-    print(f"Spatial sample shape: {spatial_sample.shape}")
-    
-    # Post-process
-    spatial_sample = th.clamp(spatial_sample, 0, 1)
-    
-    # Apply brain mask from first available modality
-    first_modality = list(available_modalities.values())[0].to(device)
-    if first_modality.dim() == 4:
-        first_modality = first_modality.unsqueeze(1)
-    
-    spatial_sample[first_modality == 0] = 0
-    
-    # Remove batch and channel dimensions
-    if spatial_sample.dim() == 5:
-        spatial_sample = spatial_sample.squeeze(1)  # Remove channel
-    spatial_sample = spatial_sample[0]  # Remove batch
-    
-    print(f"Final output shape: {spatial_sample.shape}")
-    
-    # Calculate comprehensive metrics if target is provided
-    metrics = {}
-    if metrics_calculator is not None and target_data is not None:
-        print(f"üß† Calculating brain-masked metrics...")
-        metrics = metrics_calculator.calculate_metrics(
-            spatial_sample, target_data, f"{missing_modality}_synthesis"
-        )
-        print(f"  L1: {metrics['l1']:.6f}")
-        print(f"  MSE: {metrics['mse']:.6f}")
-        print(f"  PSNR: {metrics['psnr']:.2f} dB")
-        print(f"  SSIM: {metrics['ssim']:.4f} (brain-masked)")
-        print(f"  Brain volume: {metrics['brain_volume_ratio']:.1%} of total")
-    
     # Add timing info to metrics
     if metrics:
-        metrics.update(timing_info)
+        metrics['sample_time'] = sample_duration
+        metrics['steps'] = diffusion.num_timesteps
     else:
-        metrics = timing_info
+        metrics = {'sample_time': sample_duration, 'steps': diffusion.num_timesteps}
     
-    return spatial_sample, metrics
-
+    return synthesized, metrics
 
 def save_result(synthesized, case_dir, missing_modality, output_dir):
     """Save the synthesized modality with proper uncropping."""
@@ -567,26 +325,25 @@ def save_result(synthesized, case_dir, missing_modality, output_dir):
         synthesized_np = synthesized.detach().cpu().numpy()
         print(f"  Synthesized shape before uncrop: {synthesized_np.shape}")
         
-        # Uncrop from (160, 224, 155) back to (240, 240, 155)
-        uncropped_np = apply_uncrop(synthesized_np)
+        # Uncrop from (160, 224, 160) back to (240, 240, 160)
+        uncropped_np = apply_uncrop_to_original(synthesized_np)
         print(f"  After uncropping: {uncropped_np.shape}")
         
         # Create NIfTI image
         synthesized_img = nib.Nifti1Image(uncropped_np, reference_img.affine, reference_img.header)
     else:
         synthesized_np = synthesized.detach().cpu().numpy()
-        uncropped_np = apply_uncrop(synthesized_np)
+        uncropped_np = apply_uncrop_to_original(synthesized_np)
         synthesized_img = nib.Nifti1Image(uncropped_np, np.eye(4))
     
     nib.save(synthesized_img, output_path)
     print(f"‚úÖ Saved: {output_path}")
 
-
 def process_case(case_dir, output_dir, checkpoint_dir, device, metrics_calculator=None, 
                 evaluation_mode=False, target_modality=None, override_steps=None):
-    """Process a single case with optional metrics evaluation."""
+    """Process a single case using SHARED synthesis pipeline."""
     case_name = os.path.basename(case_dir)
-    print(f"\n=== Processing {case_name} ===")
+    print(f"\n=== Processing {case_name} (SHARED PIPELINE) ===")
     
     # Check if case is complete (for evaluation mode)
     if evaluation_mode and not check_complete_case(case_dir):
@@ -624,7 +381,7 @@ def process_case(case_dir, output_dir, checkpoint_dir, device, metrics_calculato
         # Find checkpoint
         checkpoint_path = find_checkpoint(missing_modality, checkpoint_dir)
         
-        # Synthesize
+        # Synthesize using SHARED function
         synthesized, metrics = synthesize_modality(
             available_modalities, missing_modality, checkpoint_path, device,
             metrics_calculator, target_data, override_steps
@@ -636,7 +393,7 @@ def process_case(case_dir, output_dir, checkpoint_dir, device, metrics_calculato
         else:
             print(f"üìä Evaluation mode: skipping file save for {case_name}")
         
-        print(f"‚úÖ Successfully processed {case_name}")
+        print(f"‚úÖ Successfully processed {case_name} using SHARED synthesis pipeline")
         return True, metrics
         
     except Exception as e:
@@ -645,9 +402,8 @@ def process_case(case_dir, output_dir, checkpoint_dir, device, metrics_calculato
         traceback.print_exc()
         return False, {}
 
-
 def main():
-    parser = argparse.ArgumentParser(description="Enhanced medical image synthesis with VALIDATED crop bounds and brain-masked comprehensive metrics")
+    parser = argparse.ArgumentParser(description="Enhanced medical image synthesis using SHARED synthesis utilities")
     parser.add_argument("--input_dir", default="./datasets/BRATS2023/pseudo_validation")
     parser.add_argument("--output_dir", default="./datasets/BRATS2023/pseudo_validation_completed")
     parser.add_argument("--checkpoint_dir", default="./checkpoints")
@@ -682,7 +438,8 @@ def main():
     if args.diffusion_steps:
         print(f"üéØ Overriding diffusion steps: {args.diffusion_steps}")
     
-    print(f"üß† Enhanced synthesis with VALIDATED WAVELET-FRIENDLY crop bounds")
+    print(f"üß† Enhanced synthesis with SHARED SYNTHESIS UTILITIES")
+    print(f"   This ensures 100% consistency between training validation and inference")
     print(f"   Crop bounds: {CROP_BOUNDS}")
     print(f"   Cropped shape: {CROPPED_SHAPE}")
     print(f"   Memory reduction: ~42%")
@@ -771,8 +528,9 @@ def main():
     
     # Print comprehensive metrics summary
     if args.evaluate_metrics and any(all_metrics.values()):
-        print(f"\n=== üß† BRAIN-MASKED COMPREHENSIVE METRICS SUMMARY ===")
+        print(f"\n=== üß† BRAIN-MASKED COMPREHENSIVE METRICS (SHARED PIPELINE) ===")
         print(f"Using VALIDATED WAVELET-FRIENDLY crop bounds with {CROPPED_SHAPE} dimensions")
+        print(f"üîÑ SHARED synthesis utilities ensure 100% consistency with training validation")
         for modality, metrics_list in all_metrics.items():
             if metrics_list:
                 print(f"\n{modality.upper()} Synthesis:")
@@ -812,10 +570,11 @@ def main():
                 
                 print(f"  Cases: {len(metrics_list)}")
     
-    print(f"\n‚úÖ FAST-CWDM with VALIDATED CROP BOUNDS complete!")
+    print(f"\n‚úÖ ENHANCED FAST-CWDM with SHARED SYNTHESIS UTILITIES complete!")
+    print(f"   üîÑ 100% consistency between training validation and inference")
     print(f"   Memory efficiency: ~42% reduction")
     print(f"   Brain preservation: 100% validated")
-    print(f"   DWT compatibility: Perfect (160x224x155)")
+    print(f"   DWT compatibility: Perfect (160x224x160)")
 
 
 if __name__ == "__main__":
diff --git a/fast_cwdm/scripts/train.py b/fast_cwdm/scripts/train.py
index 0e23b73..2e72c66 100644
--- a/fast_cwdm/scripts/train.py
+++ b/fast_cwdm/scripts/train.py
@@ -1,5 +1,5 @@
 """
-A script for training a diffusion model for paired image-to-image translation.
+Enhanced training script with proper train/val split and validation-based model selection.
 """
 
 import argparse
@@ -53,25 +53,70 @@ def main():
 
     dist_util.setup_dist(devices=args.devices)
 
-    # Log sample schedule configuration
-    print(f"[SCHEDULE] sample_schedule: {getattr(args, 'sample_schedule', 'direct')}")
-    print(f"[SCHEDULE] diffusion_steps: {getattr(args, 'diffusion_steps', 1000)}")
+    # Log configuration
+    print(f"[CONFIG] sample_schedule: {getattr(args, 'sample_schedule', 'direct')}")
+    print(f"[CONFIG] diffusion_steps: {getattr(args, 'diffusion_steps', 1000)}")
+    print(f"[CONFIG] val_split_ratio: {args.val_split_ratio}")
+    print(f"[CONFIG] val_interval: {args.val_interval}")
+    print(f"[CONFIG] early_stopping_patience: {args.early_stopping_patience}")
+    
     print("Creating model and diffusion...")
     arguments = args_to_dict(args, model_and_diffusion_defaults().keys())
     model, diffusion = create_model_and_diffusion(**arguments)
     model.to(dist_util.dev([0, 1]) if len(args.devices) > 1 else dist_util.dev())
     schedule_sampler = create_named_schedule_sampler(args.schedule_sampler, diffusion, maxt=diffusion.num_timesteps)
+    
     if args.dataset == 'brats':
-        ds = BRATSVolumes(args.data_dir, mode='train')
-    datal = th.utils.data.DataLoader(ds,
-                                     batch_size=args.batch_size,
-                                     num_workers=args.num_workers,
-                                     shuffle=True,)
-    print("Start training...")
+        # Create training dataset
+        print("üöÇ Creating training dataset...")
+        ds_train = BRATSVolumes(
+            args.data_dir, 
+            mode='train', 
+            split='train',
+            val_split_ratio=args.val_split_ratio,
+            seed=args.seed
+        )
+        
+        # Create validation dataset
+        print("üß™ Creating validation dataset...")
+        ds_val = BRATSVolumes(
+            args.data_dir,
+            mode='train',  # Same directory, different split
+            split='val', 
+            val_split_ratio=args.val_split_ratio,
+            seed=args.seed
+        )
+        
+        print(f"‚úÖ Dataset split complete:")
+        print(f"   Training: {len(ds_train)} cases")
+        print(f"   Validation: {len(ds_val)} cases")
+        print(f"   Split ratio: {args.val_split_ratio}")
+        
+        # Log split info to wandb
+        wandb.log({
+            'dataset/train_cases': len(ds_train),
+            'dataset/val_cases': len(ds_val),
+            'dataset/total_cases': len(ds_train) + len(ds_val),
+            'dataset/val_ratio': args.val_split_ratio
+        })
+    
+    # Create data loaders
+    datal_train = th.utils.data.DataLoader(
+        ds_train,
+        batch_size=args.batch_size,
+        num_workers=args.num_workers,
+        shuffle=True,
+    )
+    
+    # Note: Validation dataset is passed directly to TrainLoop, not as DataLoader
+    # because validation is done on individual cases, not batches
+    
+    print("üöÄ Starting enhanced training with validation...")
     TrainLoop(
         model=model,
         diffusion=diffusion,
-        data=datal,
+        data=datal_train,
+        val_data=ds_val,  # NEW: Pass validation dataset
         batch_size=args.batch_size,
         in_channels=args.in_channels,
         image_size=args.image_size,
@@ -80,6 +125,7 @@ def main():
         ema_rate=args.ema_rate,
         log_interval=args.log_interval,
         save_interval=args.save_interval,
+        val_interval=args.val_interval,  # NEW: Validation interval
         resume_checkpoint=args.resume_checkpoint,
         resume_step=args.resume_step,
         use_fp16=args.use_fp16,
@@ -88,11 +134,12 @@ def main():
         weight_decay=args.weight_decay,
         lr_anneal_steps=args.lr_anneal_steps,
         dataset=args.dataset,
-        summary_writer=None,
+        summary_writer=summary_writer,
         mode='i2i',
         contr=args.contr,
         sample_schedule=args.sample_schedule,
         diffusion_steps=args.diffusion_steps,
+        early_stopping_patience=args.early_stopping_patience,  # NEW: Early stopping
     ).run_loop()
 
 
@@ -109,6 +156,9 @@ def create_argparser():
         ema_rate="0.9999",
         log_interval=100,
         save_interval=5000,
+        val_interval=100,  # NEW: Validate every 100 steps
+        val_split_ratio=0.2,  # NEW: 20% of data for validation
+        early_stopping_patience=10,  # NEW: Stop if no improvement for 10 validations
         resume_checkpoint='',
         resume_step=0,
         use_fp16=False,
@@ -130,7 +180,7 @@ def create_argparser():
         additive_skips=False,
         use_freq=False,
         contr='t1n',
-        sample_schedule='direct',         # NEW: 'direct' or 'sampled'
+        sample_schedule='direct',
     )
     from guided_diffusion.script_util import model_and_diffusion_defaults, add_dict_to_argparser
     defaults.update(model_and_diffusion_defaults())
@@ -141,4 +191,4 @@ def create_argparser():
 
 
 if __name__ == "__main__":
-    main()
+    main()
\ No newline at end of file
diff --git a/transfer-learning/ft_synth.py b/transfer-learning/ft_synth.py
index 1646f32..8e22d92 100644
--- a/transfer-learning/ft_synth.py
+++ b/transfer-learning/ft_synth.py
@@ -1,744 +1,247 @@
-#!/usr/bin/env python3
 """
-BraTS Modality Synthesis - Transfer Learning from Segmentation Model
-ENHANCED VERSION: Frequent sample logging with all input modalities visible
-FIXED: Spatial dimension errors in validation
+Shared synthesis utilities for both training validation and inference.
+Contains comprehensive metrics calculation with brain masking.
 """
 
-import os
-import glob
-import argparse
+import torch as th
 import numpy as np
-import matplotlib.pyplot as plt
-from functools import partial
-import time
-import warnings
-
-import torch
-import torch.nn as nn
+from fast_cwdm.DWT_IDWT.DWT_IDWT_layer import DWT_3D, IDWT_3D
+from monai.metrics import SSIMMetric, PSNRMetric
 import torch.nn.functional as F
-import wandb
-
-from monai.inferers import sliding_window_inference
-from monai import transforms
-from monai.transforms import AsDiscrete, Activations, DivisiblePadd, Resized
-from monai.networks.nets import SwinUNETR
-from monai.data import Dataset, DataLoader
-from monai.metrics import PSNRMetric, SSIMMetric
-
-# Suppress numpy warnings for cleaner output
-warnings.filterwarnings("ignore", category=RuntimeWarning)
 
+# VALIDATED WAVELET-FRIENDLY CROP BOUNDS
+CROP_BOUNDS = {
+    'x_min': 39, 'x_max': 199,  # width: 160 (divisible by 16)
+    'y_min': 9, 'y_max': 233,  # height: 224 (divisible by 16)
+    'z_min': 0,  'z_max': 160   # depth: 160 (original)
+}
 
-class AverageMeter(object):
-    def __init__(self):
-        self.reset()
+ORIGINAL_SHAPE = (240, 240, 160)
+CROPPED_SHAPE = (160, 224, 160)
+MODALITIES = ['t1n', 't1c', 't2w', 't2f']
 
-    def reset(self):
-        self.val = 0
-        self.avg = 0
-        self.sum = 0
-        self.count = 0
 
-    def update(self, val, n=1):
-        self.val = val
-        self.sum += val * n
-        self.count += n
-        if self.count > 0:
-            self.avg = self.sum / self.count
-        else:
-            self.avg = self.sum
-
-
-class SynthesisModel(nn.Module):
-    """Adapt SwinUNETR from segmentation to synthesis"""
+def create_brain_mask_from_target(target, threshold=0.01):
+    """Create brain mask from target image"""
+    if target.dim() > 3:
+        # Remove batch/channel dimensions for mask creation
+        target_for_mask = target.squeeze()
+    else:
+        target_for_mask = target
     
-    def __init__(self, pretrained_seg_path=None, output_channels=1):
-        super().__init__()
-        # Always use 4 input channels
-        self.backbone = SwinUNETR(
-            in_channels=4,
-            out_channels=3,
-            feature_size=48,
-            drop_rate=0.0,
-            attn_drop_rate=0.0,
-            dropout_path_rate=0.0,
-            use_checkpoint=True,
-        )
-        if pretrained_seg_path and os.path.exists(pretrained_seg_path):
-            print(f"Loading pretrained segmentation weights from: {pretrained_seg_path}")
-            checkpoint = torch.load(pretrained_seg_path, map_location='cpu', weights_only=False)
-            self.backbone.load_state_dict(checkpoint['model_state_dict'])
-            print(f"‚úì Loaded weights from epoch {checkpoint['epoch']}")
-            print(f"‚úì Segmentation dice: {checkpoint.get('val_acc_max', 'N/A')}")
-        # Replace output head for synthesis (1 channel output)
-        in_channels = self.backbone.out.conv.in_channels
-        self.backbone.out = nn.Conv3d(
-            in_channels,
-            output_channels,
-            kernel_size=1,
-            padding=0
-        )
-        print(f"‚úì Model adapted: 4 input ‚Üí {output_channels} output channels")
-
-    def forward(self, x):
-        return self.backbone(x)
-
-
-class SimplePerceptualLoss(nn.Module):
-    """Simple perceptual loss using L1 loss (placeholder for full perceptual loss)"""
+    brain_mask = (target_for_mask > threshold).float()
     
-    def __init__(self, weight=1.0):
-        super().__init__()
-        self.weight = weight
-        self.l1_loss = nn.L1Loss()
-        
-    def forward(self, pred, target):
-        # For now, just use L1 loss
-        # In a full implementation, you'd use pretrained VGG features
-        return self.weight * self.l1_loss(pred, target)
-
-
-from monai.losses import DiceLoss
-
-class DiceSynthesisLoss(nn.Module):
-    """Dice loss for synthesis (for single-channel output)"""
-    def __init__(self):
-        super().__init__()
-        self.dice = DiceLoss(include_background=True, to_onehot_y=False, sigmoid=True, reduction="mean")
-
-    def forward(self, pred, target):
-        loss = self.dice(pred, target)
-        return loss, {"dice": loss.item()}
+    # Ensure mask has same dimensions as target
+    while brain_mask.dim() < target.dim():
+        brain_mask = brain_mask.unsqueeze(0)
+    
+    return brain_mask
 
 
-class FrequentSampleLogger:
-    """WandB logger for frequent synthesis sample tracking"""
+class ComprehensiveMetrics:
+    """Calculate comprehensive metrics for synthesis evaluation with brain masking"""
     
-    def __init__(self, target_modality):
-        self.target_modality = target_modality
-        self.step = 0
-        self.samples_logged = 0
-        
-        # Define input modality names based on target
-        all_modalities = ["FLAIR", "T1CE", "T1", "T2"]
-        self.input_modalities = [mod for mod in all_modalities if mod != target_modality]
-        print(f"Input modalities: {self.input_modalities}")
-        print(f"Target modality: {target_modality}")
+    def __init__(self, device='cuda'):
+        self.device = device
+        self.ssim_metric = SSIMMetric(
+            spatial_dims=3,
+            data_range=1.0,
+            win_size=7,  # Smaller window for medical images
+            k1=0.01,
+            k2=0.03
+        )
+        self.psnr_metric = PSNRMetric(max_val=1.0)
         
-    def log_training_metrics(self, epoch, batch_idx, total_batches, loss, loss_components, lr):
-        """Log training metrics - reasonable frequency"""
-        # Log every 25 batches or 5% of epoch progress
-        log_frequency = max(25, total_batches // 20)
+    def calculate_metrics(self, predicted, target, case_name=""):
+        """Calculate L1, MSE, PSNR, and SSIM metrics with brain masking"""
+        metrics = {}
         
-        if batch_idx % log_frequency == 0:
-            wandb.log({
-                "train/loss": loss,
-                "train/dice_loss": loss_components["dice"],
-                "train/learning_rate": lr,
-                "train/epoch": epoch + 1,
-                "train/batch": batch_idx,
-                "train/progress": (epoch * total_batches + batch_idx) / (50 * total_batches)
-            }, step=self.step)
-            self.step += 1
-    
-    def log_training_samples(self, model, input_data, target_data, batch_data, epoch, batch_idx):
-        """Log samples DURING training - early and often!"""
-        try:
-            model.eval()
-            with torch.no_grad():
-                predicted = model(input_data[:1])  # Just first sample to save memory
-                
-                # Get case name
-                case_name = batch_data.get("case_id", [f"epoch{epoch+1}_batch{batch_idx}"])[0]
+        with th.no_grad():
+            # Ensure tensors are on the same device
+            predicted = predicted.to(self.device)
+            target = target.to(self.device)
+            
+            # Add channel dimension if needed
+            if predicted.dim() == 3:  # [H, W, D]
+                predicted = predicted.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W, D]
+            elif predicted.dim() == 4:  # [B, H, W, D] or [1, H, W, D]
+                predicted = predicted.unsqueeze(1)  # [B, 1, H, W, D]
                 
-                # Log single sample with all 3 input modalities
-                self._log_detailed_sample(
-                    input_data[0].cpu().numpy(),
-                    target_data[0].cpu().numpy(), 
-                    predicted[0].cpu().numpy(),
-                    case_name,
-                    f"TRAINING | Epoch {epoch+1} Batch {batch_idx}"
-                )
-            model.train()
-        except Exception as e:
-            print(f"Error logging training sample: {e}")
-    
-    def log_validation_samples(self, inputs, targets, predictions, case_names, epoch, split="val"):
-        """Log validation samples - show more detail"""
-        try:
-            for i in range(min(5, len(inputs))):  # Show up to 5 validation samples
-                self._log_detailed_sample(
-                    inputs[i], targets[i], predictions[i], case_names[i],
-                    f"VALIDATION | Epoch {epoch+1}"
-                )
-        except Exception as e:
-            print(f"Error logging validation samples: {e}")
-    
-    def _log_detailed_sample(self, input_vol, target_vol, pred_vol, case_name, stage_info):
-        """Log detailed sample showing all 3 input modalities - FIXED with brain masking"""
-        try:
-            # Get middle slice
-            slice_idx = input_vol.shape[-1] // 2
+            if target.dim() == 3:
+                target = target.unsqueeze(0).unsqueeze(0)
+            elif target.dim() == 4:
+                target = target.unsqueeze(1)
             
-            # Extract all slices
-            input1_slice = input_vol[0, :, :, slice_idx]  # First input modality
-            input2_slice = input_vol[1, :, :, slice_idx]  # Second input modality  
-            input3_slice = input_vol[2, :, :, slice_idx]  # Third input modality
-            target_slice = target_vol[0, :, :, slice_idx]
-            pred_slice = pred_vol[0, :, :, slice_idx]
+            # üß† CREATE BRAIN MASK FROM TARGET (GROUND TRUTH)
+            brain_mask = create_brain_mask_from_target(target, threshold=0.01)
             
-            # ‚úÖ USE BRAIN-AWARE NORMALIZATION
-            def normalize_for_visualization(img):
-                mask = img > 0.01
-                if np.any(mask):
-                    img_masked = img[mask]
-                    minv, maxv = img_masked.min(), img_masked.max()
-                    norm = np.zeros_like(img)
-                    if maxv > minv:
-                        norm[mask] = (img[mask] - minv) / (maxv - minv)
-                    return norm
-                else:
-                    return img
+            # üß† APPLY MASK TO BOTH PREDICTED AND TARGET
+            predicted_masked = predicted * brain_mask
+            target_masked = target * brain_mask
             
-            all_images = [input1_slice, input2_slice, input3_slice, target_slice, pred_slice]
-            normalized_images = [normalize_for_visualization(img) for img in all_images]
-            comparison = np.concatenate(normalized_images, axis=1)
-            comparison_rgb = np.stack([comparison] * 3, axis=-1)
+            # Calculate metrics on MASKED images only
+            l1_loss = F.l1_loss(predicted_masked, target_masked).item()
+            mse_loss = F.mse_loss(predicted_masked, target_masked).item()
             
-            # Create detailed caption
-            modality_labels = " | ".join([
-                f"{self.input_modalities[0]} INPUT",
-                f"{self.input_modalities[1]} INPUT", 
-                f"{self.input_modalities[2]} INPUT",
-                f"{self.target_modality} TARGET",
-                f"{self.target_modality} PREDICTED"
-            ])
+            # PSNR on masked images
+            try:
+                psnr_score = self.psnr_metric(y_pred=predicted_masked, y=target_masked).mean().item()
+            except Exception as e:
+                print(f"  Warning: PSNR calculation failed for {case_name}: {e}")
+                psnr_score = 0.0
             
-            caption = f"{stage_info} | {case_name} | {modality_labels} | BRAIN-MASKED"
+            # SSIM on masked images - KEY METRIC FOR VALIDATION!
+            try:
+                ssim_score = self.ssim_metric(y_pred=predicted_masked, y=target_masked).mean().item()
+            except Exception as e:
+                print(f"  Warning: SSIM calculation failed for {case_name}: {e}")
+                ssim_score = 0.0
             
-            # Log with sample counter for easy tracking
-            wandb.log({
-                f"samples/detailed_synthesis": wandb.Image(comparison_rgb, caption=caption),
-                f"samples/count": self.samples_logged
-            }, step=self.step)
+            # Calculate brain volume for debugging/reporting
+            brain_volume = brain_mask.sum().item()
+            total_volume = brain_mask.numel()
+            brain_ratio = brain_volume / total_volume
             
-            self.samples_logged += 1
-            self.step += 1
+            metrics = {
+                'l1': l1_loss,
+                'mse': mse_loss,
+                'psnr': psnr_score,
+                'ssim': ssim_score,
+                'brain_volume_ratio': brain_ratio
+            }
             
-        except Exception as e:
-            print(f"Error creating detailed sample: {e}")
-    
-    def log_epoch_summary(self, epoch, train_loss, val_metrics, epoch_time):
-        """Log epoch summary"""
-        wandb.log({
-            "epoch": epoch + 1,
-            "summary/train_loss": train_loss,
-            "summary/val_l1": val_metrics["l1"],
-            "summary/val_psnr": val_metrics.get("psnr", 0.0),
-            "summary/val_ssim": val_metrics.get("ssim", 0.0),
-            "summary/epoch_time": epoch_time,
-            "summary/samples_logged_total": self.samples_logged
-        }, step=self.step)
-        self.step += 1
-    
-    def log_best_model(self, epoch, val_l1, model_path):
-        """Log when best model is saved"""
-        wandb.log({
-            "best_model/epoch": epoch + 1,
-            "best_model/val_l1": val_l1,
-            "best_model/saved": True
-        }, step=self.step)
-        self.step += 1
+        return metrics
 
 
-def find_brats_cases(data_dir, target_modality="T1CE"):
-    """Find BraTS cases and set up for synthesis"""
-    cases = []
+def prepare_conditioning(available_modalities, missing_modality, device):
+    """Prepare conditioning tensor from available modalities with FIXED dimensions."""
+    dwt = DWT_3D("haar")
     
-    print(f"Scanning {data_dir} for BraTS synthesis cases...")
-    print(f"Target modality for synthesis: {target_modality}")
+    # Get modalities in consistent order
+    available_order = [m for m in MODALITIES if m != missing_modality]
     
-    if not os.path.exists(data_dir):
-        print(f"ERROR: Directory {data_dir} does not exist!")
-        return cases
+    cond_list = []
     
-    # Modality mapping
-    modality_files = {
-        "FLAIR": "t2f.nii.gz",
-        "T1CE": "t1c.nii.gz", 
-        "T1": "t1n.nii.gz",
-        "T2": "t2w.nii.gz"
-    }
-
-    for item in os.listdir(data_dir):
-        if 'BraTS' in item and os.path.isdir(os.path.join(data_dir, item)):
-            case_path = os.path.join(data_dir, item)
-            # Build file paths
-            files = {}
-            for modality, suffix in modality_files.items():
-                files[modality] = os.path.join(case_path, f"{item}-{suffix}")
-            # Check if all files exist
-            if all(os.path.exists(f) for f in files.values()):
-                # Always use 4 input channels: copy one modality if needed
-                input_modalities = [mod for mod in modality_files.keys() if mod != target_modality]
-                input_images = [files[mod] for mod in input_modalities]
-                # Copy FLAIR (or T1CE if FLAIR is target) to keep 4 channels
-                if len(input_images) == 3:
-                    if target_modality != "FLAIR":
-                        input_images.append(files["FLAIR"])
-                    else:
-                        input_images.append(files["T1CE"])
-                case_data = {
-                    "input_image": input_images,
-                    "target_image": files[target_modality],
-                    "case_id": item,
-                    "target_modality": target_modality
-                }
-                cases.append(case_data)
-                if len(cases) % 50 == 0:
-                    print(f"Found {len(cases)} valid synthesis cases so far...")
-    print(f"Finished scanning synthesis data. Total cases found: {len(cases)}")
-    print(f"Input modalities: always 4 (one copied if needed)")
-    print(f"Target modality: {target_modality}")
-    return cases
-
-
-def frequent_sample_train_epoch(model, loader, optimizer, epoch, loss_func, max_epochs, target_modality, logger):
-    """Training with frequent sample logging"""
-    model.train()
-    run_loss = AverageMeter()
-    run_dice = AverageMeter()
-    
-    for idx, batch_data in enumerate(loader):
-        input_data = batch_data["input_image"].cuda()
-        target_data = batch_data["target_image"].cuda()
+    for modality in available_order:
+        # Get tensor and add channel dimension
+        tensor = available_modalities[modality].to(device)
+        if tensor.dim() == 4:
+            tensor = tensor.unsqueeze(1)  # [B, 1, H, W, D]
         
-        optimizer.zero_grad()
-        predicted = model(input_data)
-        total_loss, loss_components = loss_func(predicted, target_data)
-        total_loss.backward()
-        optimizer.step()
+        # Apply DWT - should work perfectly with (160, 224, 160) dimensions
+        dwt_components = dwt(tensor)
         
-        # Update metrics
-        run_loss.update(total_loss.item(), n=input_data.shape[0])
-        run_dice.update(loss_components["dice"], n=input_data.shape[0])
+        # All components should have consistent dimensions now
+        LLL, LLH, LHL, LHH, HLL, HLH, HHL, HHH = dwt_components
         
-        # Log training metrics
-        logger.log_training_metrics(
-            epoch, idx, len(loader), 
-            total_loss.item(), loss_components, 
-            optimizer.param_groups[0]['lr']
-        )
+        # Create DWT conditioning tensor
+        modality_cond = th.cat([
+            LLL / 3.,  # Divide LLL by 3 as per training
+            LLH, LHL, LHH, HLL, HLH, HHL, HHH
+        ], dim=1)
         
-        # LOG SAMPLES FREQUENTLY - every 15 batches in early epochs, less frequent later
-        if epoch < 5:
-            sample_freq = 15  # Very frequent early on
-        elif epoch < 20:
-            sample_freq = 30  # Medium frequency
-        else:
-            sample_freq = 50  # Less frequent later
-            
-        if (idx + 1) % sample_freq == 0:
-            print(f"Logging training sample at epoch {epoch+1}, batch {idx+1}")
-            logger.log_training_samples(model, input_data, target_data, batch_data, epoch, idx)
+        cond_list.append(modality_cond)
+    
+    # Concatenate all modalities
+    cond = th.cat(cond_list, dim=1)
+    return cond
+
+
+def synthesize_modality_shared(model, diffusion, available_modalities, missing_modality, device, 
+                              metrics_calculator=None, target_data=None):
+    """
+    Shared synthesis function used by both training validation and inference.
+    
+    Args:
+        model: The diffusion model
+        diffusion: The diffusion process
+        available_modalities: Dict of available modality tensors
+        missing_modality: String name of missing modality
+        device: torch device
+        metrics_calculator: Optional ComprehensiveMetrics instance
+        target_data: Optional ground truth tensor for metrics
+    
+    Returns:
+        synthesized_tensor: The synthesized modality
+        metrics: Dict of calculated metrics (if target provided)
+    """
+    
+    # Prepare conditioning
+    cond = prepare_conditioning(available_modalities, missing_modality, device)
+    
+    # Create noise tensor with CORRECT dimensions based on DWT output
+    _, _, cond_d, cond_h, cond_w = cond.shape
+    noise_shape = (1, 8, cond_d, cond_h, cond_w)  # Match DWT dimensions
+    noise = th.randn(*noise_shape, device=device)
+    
+    # Sample using p_sample_loop_progressive
+    with th.no_grad():
+        final_sample = None
+        for sample_dict in diffusion.p_sample_loop_progressive(
+            model=model,
+            shape=noise.shape,
+            time=diffusion.num_timesteps,
+            noise=noise,
+            cond=cond,
+            clip_denoised=True,
+            model_kwargs={}
+        ):
+            final_sample = sample_dict
         
-        # Progress print
-        if (idx + 1) % 20 == 0:
-            print(f"Epoch {epoch+1}/{max_epochs} [{idx+1}/{len(loader)}] "
-                  f"Loss: {run_loss.avg:.4f} Dice: {run_dice.avg:.4f}")
-    
-    return run_loss.avg
-
-
-def frequent_sample_val_epoch(model, loader, epoch, max_epochs, target_modality, logger):
-    """Validation with frequent sample logging - FIXED for spatial dimension issues"""
-    model.eval()
-    run_l1 = AverageMeter()
-    run_psnr = AverageMeter()
-    run_ssim = AverageMeter()
-    
-    # Collect samples for logging
-    sample_inputs, sample_targets, sample_preds, sample_names = [], [], [], []
-    
-    # ROI size for sliding window inference
-    roi = (128, 128, 128)
-    
-    with torch.no_grad():
-        for idx, batch_data in enumerate(loader):
-            try:
-                input_data = batch_data["input_image"].cuda()
-                target_data = batch_data["target_image"].cuda()
-                
-                # Use sliding window inference for variable-sized validation images
-                # This handles the spatial dimension divisibility issue
-                predicted = sliding_window_inference(
-                    inputs=input_data,
-                    roi_size=roi,
-                    sw_batch_size=1,
-                    predictor=model,
-                    overlap=0.5,
-                    mode="gaussian",
-                    sigma_scale=0.125,
-                    padding_mode="constant",
-                    cval=0.0,
-                )
-                
-                # Compute metrics
-                l1_loss = torch.nn.functional.l1_loss(predicted, target_data)
-                run_l1.update(l1_loss.item(), n=input_data.shape[0])
-                
-                # PSNR and SSIM (handle potential errors)
-                try:
-                    psnr_metric = PSNRMetric(max_val=1.0)
-                    ssim_metric = SSIMMetric(spatial_dims=3)
-                    psnr_val = psnr_metric(predicted, target_data).item()
-                    ssim_val = ssim_metric(predicted, target_data).item()
-                    run_psnr.update(psnr_val, n=input_data.shape[0])
-                    run_ssim.update(ssim_val, n=input_data.shape[0])
-                except Exception as metric_error:
-                    print(f"Warning: Metric computation failed for batch {idx}: {metric_error}")
-                    # Set default values if metrics fail
-                    run_psnr.update(0.0, n=input_data.shape[0])
-                    run_ssim.update(0.0, n=input_data.shape[0])
-                
-                # Collect samples (more samples for better coverage)
-                if len(sample_inputs) < 8:  # Increased from 3 to 8
-                    sample_inputs.append(input_data[0].cpu().numpy())
-                    sample_targets.append(target_data[0].cpu().numpy())
-                    sample_preds.append(predicted[0].cpu().numpy())
-                    sample_names.append(batch_data.get("case_id", [f"val_case_{idx}"])[0])
-                
-                if (idx + 1) % 10 == 0:
-                    print(f"Val [{idx+1}/{len(loader)}] L1: {run_l1.avg:.6f}")
-                    
-            except Exception as e:
-                print(f"Error in validation step {idx}: {e}")
-                # Log more details about the error
-                if hasattr(e, 'args') and 'spatial dimensions' in str(e):
-                    print(f"  Input shape: {input_data.shape if 'input_data' in locals() else 'N/A'}")
-                    print(f"  Target shape: {target_data.shape if 'target_data' in locals() else 'N/A'}")
-                continue
-    
-    # Log validation samples EVERY epoch (not just every 5)
-    print(f"Logging {len(sample_inputs)} validation samples for epoch {epoch+1}")
-    logger.log_validation_samples(
-        sample_inputs, sample_targets, sample_preds, sample_names, epoch, "val"
+        sample = final_sample["sample"]
+    
+    # Convert back to spatial domain using IDWT
+    idwt = IDWT_3D("haar")
+    B, _, D, H, W = sample.shape
+    
+    spatial_sample = idwt(
+        sample[:, 0, :, :, :].view(B, 1, D, H, W) * 3.,  # Multiply LLL by 3
+        sample[:, 1, :, :, :].view(B, 1, D, H, W),
+        sample[:, 2, :, :, :].view(B, 1, D, H, W),
+        sample[:, 3, :, :, :].view(B, 1, D, H, W),
+        sample[:, 4, :, :, :].view(B, 1, D, H, W),
+        sample[:, 5, :, :, :].view(B, 1, D, H, W),
+        sample[:, 6, :, :, :].view(B, 1, D, H, W),
+        sample[:, 7, :, :, :].view(B, 1, D, H, W)
     )
     
-    return {"l1": run_l1.avg, "psnr": run_psnr.avg, "ssim": run_ssim.avg}
-
-
-def get_fixed_transforms(roi):
-    """Get fixed transforms that handle spatial dimensions properly + brain masking"""
-    from monai.transforms import MapTransform
-    class ApplyBrainMaskDict(MapTransform):
-        """Apply a brain mask to all specified keys using a reference channel and threshold."""
-        def __init__(self, keys, reference_channel=1, threshold=0.01):
-            super().__init__(keys)
-            self.reference_channel = reference_channel
-            self.threshold = threshold
-        def __call__(self, data):
-            d = dict(data)
-            ref = d[self.keys[0]][self.reference_channel] if d[self.keys[0]].ndim == 4 else d[self.keys[0]][self.reference_channel]
-            mask = (ref > self.threshold)
-            for key in self.keys:
-                arr = d[key]
-                if arr.ndim == 4:
-                    for c in range(arr.shape[0]):
-                        arr[c] = arr[c] * mask
-                else:
-                    d[key] = arr * mask
-            return d
-
-    train_transform = transforms.Compose([
-        transforms.LoadImaged(keys=["input_image", "target_image"]),
-        transforms.EnsureChannelFirstd(keys=["target_image"]),
-        transforms.NormalizeIntensityd(keys=["input_image", "target_image"], nonzero=True, channel_wise=True),
-        ApplyBrainMaskDict(keys=["input_image", "target_image"], reference_channel=1, threshold=0.01),
-        transforms.CropForegroundd(
-            keys=["input_image", "target_image"],
-            source_key="input_image",
-            k_divisible=[roi[0], roi[1], roi[2]],
-            allow_smaller=True,
-        ),
-        transforms.RandSpatialCropd(
-            keys=["input_image", "target_image"],
-            roi_size=[roi[0], roi[1], roi[2]],
-            random_size=False,
-        ),
-        transforms.RandFlipd(keys=["input_image", "target_image"], prob=0.5, spatial_axis=0),
-        transforms.RandFlipd(keys=["input_image", "target_image"], prob=0.5, spatial_axis=1),
-        transforms.RandFlipd(keys=["input_image", "target_image"], prob=0.5, spatial_axis=2),
-        transforms.RandRotate90d(keys=["input_image", "target_image"], prob=0.3, spatial_axes=(0, 1)),
-        transforms.RandScaleIntensityd(keys=["input_image", "target_image"], factors=0.1, prob=0.5),
-        transforms.RandShiftIntensityd(keys=["input_image", "target_image"], offsets=0.1, prob=0.5),
-    ])
-
-    val_transform = transforms.Compose([
-        transforms.LoadImaged(keys=["input_image", "target_image"]),
-        transforms.EnsureChannelFirstd(keys=["target_image"]),
-        transforms.NormalizeIntensityd(keys=["input_image", "target_image"], nonzero=True, channel_wise=True),
-        ApplyBrainMaskDict(keys=["input_image", "target_image"], reference_channel=1, threshold=0.01),
-        transforms.CropForegroundd(
-            keys=["input_image", "target_image"],
-            source_key="input_image",
-            k_divisible=[32, 32, 32],
-            allow_smaller=True,
-        ),
-        transforms.DivisiblePadd(
-            keys=["input_image", "target_image"],
-            k=32,
-            mode="constant",
-            constant_values=0,
-        ),
-    ])
-    return train_transform, val_transform
-
-
-def parse_args():
-    """Parse command line arguments"""
-    parser = argparse.ArgumentParser(description='BraTS Modality Synthesis with Frequent Sample Logging')
-    parser.add_argument('--pretrained_path', type=str, required=True,
-                        help='Path to pretrained segmentation model')
-    parser.add_argument('--save_path', type=str, required=True,
-                        help='Path where to save the best synthesis model')
-    parser.add_argument('--target_modality', type=str, default='T1CE',
-                        choices=['FLAIR', 'T1CE', 'T1', 'T2'],
-                        help='Target modality to synthesize')
-    parser.add_argument('--max_epochs', type=int, default=50,
-                        help='Maximum number of training epochs')
-    parser.add_argument('--use_tables', action='store_true',
-                        help='Also log results using WandB Tables for better organization')
-    return parser.parse_args()
-
-
-def main():
-    # Parse arguments
-    args = parse_args()
-    
-    # Ensure save directory exists
-    save_dir = os.path.dirname(args.save_path)
-    if save_dir and not os.path.exists(save_dir):
-        os.makedirs(save_dir, exist_ok=True)
-        print(f"Created save directory: {save_dir}")
-    
-    # Initialize W&B with frequent sample configuration
-    roi = (128, 128, 128)
-    wandb.init(
-        project="BraTS2025",
-        name=f"synthesis_{args.target_modality.lower()}_fixed",
-        config={
-            "target_modality": args.target_modality,
-            "max_epochs": args.max_epochs,
-            "pretrained_path": args.pretrained_path,
-            "save_path": args.save_path,
-            "batch_size": 2,
-            "roi": roi,
-            "optimizer": "AdamW",
-            "learning_rate": 5e-5,
-            "weight_decay": 1e-5,
-            "scheduler": "CosineAnnealingLR",
-            "loss": "Dice",
-            "use_tables": args.use_tables,
-            "logging_strategy": "frequent_samples_all_inputs",
-            "sample_frequency": "every_15_batches_early_epochs",
-            "validation_samples": "every_epoch_8_samples",
-            "input_modalities_shown": "all_3_plus_target_and_prediction",
-            "spatial_fix": "sliding_window_inference_and_divisible_padding",
-            "version": "fixed_validation"
-        }
-    )
-    
-    print("‚úì WandB initialized for frequent sample logging with FIXED spatial dimensions")
-    
-    # Setup
-    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-    print(f"Using device: {device}")
-    print(f"Target modality: {args.target_modality}")
-    print(f"Pretrained model: {args.pretrained_path}")
-    print(f"Model will be saved to: {args.save_path}")
-    
-    # Find synthesis data
-    print("Looking for BraTS data...")
-    base_dir = "/app/UNETR-BraTS-Synthesis"
-    data_dir = os.path.join(base_dir, "ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData")
-    print(f"Data directory: {data_dir}")
-
-    # Load all cases for synthesis
-    all_cases = find_brats_cases(data_dir, target_modality=args.target_modality)
-    print(f"Total synthesis cases found: {len(all_cases)}")
-
-    # Split into train/val (80% train, 20% val for synthesis)
-    np.random.seed(42)
-    np.random.shuffle(all_cases)
-    split_idx = int(0.8 * len(all_cases))
-    train_cases = all_cases[:split_idx]
-    val_cases = all_cases[split_idx:]
-
-    print(f"\n=== SYNTHESIS DATASET SUMMARY ===")
-    print(f"Training cases: {len(train_cases)}")
-    print(f"Validation cases: {len(val_cases)}")
-    print(f"Target modality: {args.target_modality}")
-    print(f"Input modalities: 3 (excluding {args.target_modality})")
-
-    if not train_cases:
-        print("No training cases found!")
-        return
-
-    # Log dataset info to W&B
-    wandb.log({
-        "dataset/train_cases": len(train_cases),
-        "dataset/val_cases": len(val_cases),
-        "dataset/target_modality": args.target_modality,
-        "dataset/pretrained_model": args.pretrained_path
-    })
+    # Post-process
+    spatial_sample = th.clamp(spatial_sample, 0, 1)
     
-    # Get FIXED transforms for synthesis
-    train_transform, val_transform = get_fixed_transforms(roi)
+    # Apply brain mask from first available modality
+    first_modality = list(available_modalities.values())[0].to(device)
+    if first_modality.dim() == 4:
+        first_modality = first_modality.unsqueeze(1)
     
-    # Data loaders
-    batch_size = 2
-    train_ds = Dataset(data=train_cases, transform=train_transform)
-    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)
+    spatial_sample[first_modality == 0] = 0
     
-    val_ds = Dataset(data=val_cases, transform=val_transform)
-    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)
+    # Remove batch and channel dimensions
+    if spatial_sample.dim() == 5:
+        spatial_sample = spatial_sample.squeeze(1)  # Remove channel
+    spatial_sample = spatial_sample[0]  # Remove batch
     
-    print(f"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}")
-    
-    # Create synthesis model with pretrained weights
-    model = SynthesisModel(
-        pretrained_seg_path=args.pretrained_path,
-        output_channels=1
-    ).cuda()
-    
-    # Synthesis loss function
-    loss_func = DiceSynthesisLoss()
-    
-    # Training setup
-    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)
-    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.max_epochs, eta_min=1e-6)
-    
-    # Initialize frequent sample logger
-    logger = FrequentSampleLogger(args.target_modality)
-    
-    print(f"\n=== SYNTHESIS TRAINING CONFIGURATION ===")
-    print(f"Max epochs: {args.max_epochs}")
-    print(f"Learning rate: 5e-5 (reduced for transfer learning)")
-    print(f"Loss: Dice")
-    print(f"ROI size: {roi}")
-    print(f"FREQUENT SAMPLE LOGGING ENABLED")
-    print(f"Training samples: Every 15 batches (early epochs) ‚Üí 50 batches (later)")
-    print(f"Validation samples: Every epoch, up to 8 samples")
-    print(f"Showing all input modalities: {logger.input_modalities}")
-    print(f"SPATIAL DIMENSION FIX: Sliding window inference + divisible padding")
-    
-    best_l1 = float('inf')
-    
-    for epoch in range(args.max_epochs):
-        print(f"\n=== EPOCH {epoch+1}/{args.max_epochs} ===")
-        epoch_start = time.time()
-
-        # Training with frequent samples
-        train_loss = frequent_sample_train_epoch(
-            model, train_loader, optimizer, epoch, 
-            loss_func, args.max_epochs, args.target_modality, logger
-        )
-
-        print(f"EPOCH {epoch + 1} COMPLETE, avg_loss: {train_loss:.4f}, time: {time.time() - epoch_start:.2f}s")
-
-        # Validation with samples every epoch - FIXED for spatial dimensions
-        epoch_time = time.time()
-        val_metrics = frequent_sample_val_epoch(
-            model, val_loader, epoch, args.max_epochs, args.target_modality, logger
+    # Calculate comprehensive metrics if target is provided
+    metrics = {}
+    if metrics_calculator is not None and target_data is not None:
+        metrics = metrics_calculator.calculate_metrics(
+            spatial_sample, target_data, f"{missing_modality}_synthesis"
         )
+    
+    return spatial_sample, metrics
 
-        epoch_time = time.time() - epoch_time
-        
-        # Log epoch summary
-        logger.log_epoch_summary(epoch, train_loss, val_metrics, epoch_time)
-
-        print(f"VALIDATION COMPLETE: L1: {val_metrics['l1']:.6f}, PSNR: {val_metrics['psnr']:.6f}, SSIM: {val_metrics['ssim']:.6f}")
-
-        # Save best model
-        if val_metrics["l1"] < best_l1:
-            print(f"NEW BEST L1 SCORE! ({best_l1:.6f} --> {val_metrics['l1']:.6f})")
-            best_l1 = val_metrics["l1"]
-            
-            logger.log_best_model(epoch, best_l1, args.save_path)
 
-            try:
-                torch.save({
-                    'epoch': epoch + 1,
-                    'model_state_dict': model.state_dict(),
-                    'optimizer_state_dict': optimizer.state_dict(),
-                    'scheduler_state_dict': scheduler.state_dict(),
-                    'best_l1': best_l1,
-                    'val_metrics': val_metrics,
-                    'target_modality': args.target_modality,
-                    'pretrained_from': args.pretrained_path,
-                    'version': 'fixed_validation'
-                }, args.save_path)
-                print(f"‚úì Best synthesis model saved to: {args.save_path}")
-            except Exception as e:
-                print(f"ERROR saving model: {e}")
-
-        scheduler.step()
-        print(f"Epoch {epoch+1} complete in {epoch_time:.1f}s | Samples logged: {logger.samples_logged}")
+def apply_uncrop_to_original(cropped_output):
+    """Uncrop from (160,224,160) back to (240,240,160)"""
+    if isinstance(cropped_output, th.Tensor):
+        uncropped = th.zeros(ORIGINAL_SHAPE, dtype=cropped_output.dtype, device=cropped_output.device)
+    else:
+        uncropped = np.zeros(ORIGINAL_SHAPE, dtype=cropped_output.dtype)
     
-    print(f"\nüéâ TRAINING COMPLETE!")
-    print(f"üìä Total samples logged: {logger.samples_logged}")
-    print(f"üèÜ Best L1: {best_l1:.6f}")
-    print(f"‚úì Target modality: {args.target_modality}")
-    print(f"‚úì Best model saved to: {args.save_path}")
-    print(f"üîç All input modalities were visible in samples")
-    print(f"üîß Spatial dimension issues FIXED with sliding window inference")
+    # Place cropped output back in original position
+    uncropped[
+        CROP_BOUNDS['x_min']:CROP_BOUNDS['x_max'],
+        CROP_BOUNDS['y_min']:CROP_BOUNDS['y_max'],
+        CROP_BOUNDS['z_min']:CROP_BOUNDS['z_max']
+    ] = cropped_output
     
-    # Log summary to W&B
-    wandb.run.summary["best_l1"] = best_l1
-    wandb.run.summary["target_modality"] = args.target_modality
-    wandb.run.summary["best_model_path"] = args.save_path
-    wandb.run.summary["total_samples_logged"] = logger.samples_logged
-    wandb.run.summary["logging_strategy"] = "frequent_samples_all_inputs"
-    wandb.run.summary["spatial_fix"] = "sliding_window_inference_and_divisible_padding"
-    wandb.run.summary["version"] = "fixed_validation"
-    wandb.finish()
-
-
-# ---
-# Synthesis function with brain masking for inference
-def synthesize_modality(input_data, model, device):
-    """Run synthesis inference with brain masking"""
-    import nibabel as nib
-    import torch
-    # Assume input_data is a dict with 'input_image' (list of file paths)
-    # and model is already loaded and on device
-    # Load and preprocess input images
-    imgs = [nib.load(f).get_fdata() for f in input_data["input_image"]]
-    imgs = np.stack(imgs, axis=0)  # (C, H, W, D)
-    original_shape = imgs.shape[1:]
-    # Normalize (simple min-max for demo)
-    imgs = (imgs - imgs.min()) / (imgs.max() - imgs.min() + 1e-8)
-    # Add batch/channel dims for model
-    tensor = torch.from_numpy(imgs).unsqueeze(0).float().to(device)
-    with torch.no_grad():
-        prediction = model(tensor)
-    result = prediction[0, 0].cpu().numpy()  # Remove batch and channel dims
-    # ‚úÖ APPLY BRAIN MASKING TO RESULT
-    reference_img = nib.load(input_data["input_image"][0])
-    reference_data = reference_img.get_fdata()
-    brain_mask = reference_data > 0.01  # Simple threshold-based mask
-    result = result * brain_mask
-    # Crop back to original dimensions if needed
-    if result.shape != original_shape:
-        print(f"    Cropping from {result.shape} to {original_shape}")
-        # Simple center crop
-        min_shape = np.minimum(result.shape, original_shape)
-        start = [(result.shape[i] - min_shape[i]) // 2 for i in range(3)]
-        end = [start[i] + min_shape[i] for i in range(3)]
-        result = result[start[0]:end[0], start[1]:end[1], start[2]:end[2]]
-    return result
-
-if __name__ == "__main__":
-    main()
\ No newline at end of file
+    return uncropped
\ No newline at end of file
